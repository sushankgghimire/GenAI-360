# Experimenting with Language Models

In this notebook, I document my attempts to use various language models for text generation and retrieval tasks. Below is a summary of the models I've tried, the issues encountered, and my current setup.

## Models Tried

1. **Zephyr via HuggingFace Endpoint**:
   - I attempted to use the `HuggingFaceH4/zephyr-7b-beta` model through the HuggingFace endpoint.
   - Configuration:
     - `max_new_tokens=512`
     - `do_sample=False`
     - `repetition_penalty=1.5`
   - **Result**: Most outputs were gibberish, with only a few meaningful generations.

2. **Quantized Mistral using ctransformers**:
   - I also tried using a quantized version of the Mistral model through the `ctransformers` library.
   - **Result**: The output was similarly nonsensical, with very few accurate or coherent responses.

3. **Quantized LLaMA2 using LlamaCpp**:
   - Finally, I used a quantized version of LLaMA2 with the `LlamaCpp` library.
   - **Result**: As with the previous models, the majority of the generated text was gibberish.

## Current Setup

Given the inconsistent performance of the above models, I have resorted to using the Mistral API for most of the results presented here. While some outputs are indeed generated by the aforementioned models, the majority come from the Mistral API, which has proven to be more reliable.

## Issues Encountered

One recurring issue is that when attempting to use models other than the Mistral API, the `retriever_func` tool is not recognized as a valid tool in the agent execution. This has been a persistent problem, and I'm currently looking for solutions.

## Open for Suggestions

I'm open to any suggestions on how to resolve the issue of `retriever_func` not being recognized as a valid tool for models other than the Mistral API. If you have any insights or recommendations, please feel free to contribute or reach out.

