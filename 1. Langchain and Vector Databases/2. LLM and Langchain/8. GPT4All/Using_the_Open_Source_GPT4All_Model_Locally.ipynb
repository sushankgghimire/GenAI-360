{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bvZ-GEAlVuR5"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain pyllamacpp sentencepiece langchain_community gpt4all llama-cpp-python -q\n",
        "clear_output()\n",
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WowTlm4RWahw",
        "outputId": "033a157c-7fd2-4df8-8f86-1fe0f1b53e93"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                          Version\n",
            "-------------------------------- ---------------------\n",
            "absl-py                          1.4.0\n",
            "accelerate                       0.32.1\n",
            "aiohappyeyeballs                 2.4.0\n",
            "aiohttp                          3.10.5\n",
            "aiosignal                        1.3.1\n",
            "alabaster                        0.7.16\n",
            "albucore                         0.0.13\n",
            "albumentations                   1.4.14\n",
            "altair                           4.2.2\n",
            "annotated-types                  0.7.0\n",
            "anyio                            3.7.1\n",
            "argon2-cffi                      23.1.0\n",
            "argon2-cffi-bindings             21.2.0\n",
            "array_record                     0.5.1\n",
            "arviz                            0.18.0\n",
            "asn1crypto                       1.5.1\n",
            "astropy                          6.1.2\n",
            "astropy-iers-data                0.2024.8.19.0.32.16\n",
            "astunparse                       1.6.3\n",
            "async-timeout                    4.0.3\n",
            "atpublic                         4.1.0\n",
            "attrs                            24.2.0\n",
            "audioread                        3.0.1\n",
            "autograd                         1.6.2\n",
            "babel                            2.16.0\n",
            "backcall                         0.2.0\n",
            "beautifulsoup4                   4.12.3\n",
            "bidict                           0.23.1\n",
            "bigframes                        1.15.0\n",
            "bleach                           6.1.0\n",
            "blinker                          1.4\n",
            "blis                             0.7.11\n",
            "blosc2                           2.0.0\n",
            "bokeh                            3.4.3\n",
            "bqplot                           0.12.43\n",
            "branca                           0.7.2\n",
            "build                            1.2.1\n",
            "CacheControl                     0.14.0\n",
            "cachetools                       5.5.0\n",
            "catalogue                        2.0.10\n",
            "certifi                          2024.7.4\n",
            "cffi                             1.17.0\n",
            "chardet                          5.2.0\n",
            "charset-normalizer               3.3.2\n",
            "chex                             0.1.86\n",
            "clarabel                         0.9.0\n",
            "click                            8.1.7\n",
            "click-plugins                    1.1.1\n",
            "cligj                            0.7.2\n",
            "cloudpathlib                     0.18.1\n",
            "cloudpickle                      2.2.1\n",
            "cmake                            3.30.2\n",
            "cmdstanpy                        1.2.4\n",
            "colorcet                         3.1.0\n",
            "colorlover                       0.3.0\n",
            "colour                           0.1.5\n",
            "community                        1.0.0b1\n",
            "confection                       0.1.5\n",
            "cons                             0.4.6\n",
            "contextlib2                      21.6.0\n",
            "contourpy                        1.2.1\n",
            "cryptography                     43.0.0\n",
            "cuda-python                      12.2.1\n",
            "cudf-cu12                        24.4.1\n",
            "cufflinks                        0.17.3\n",
            "cupy-cuda12x                     12.2.0\n",
            "cvxopt                           1.3.2\n",
            "cvxpy                            1.5.3\n",
            "cycler                           0.12.1\n",
            "cymem                            2.0.8\n",
            "Cython                           3.0.11\n",
            "dask                             2024.7.1\n",
            "dataclasses-json                 0.6.7\n",
            "datascience                      0.17.6\n",
            "db-dtypes                        1.3.0\n",
            "dbus-python                      1.2.18\n",
            "debugpy                          1.6.6\n",
            "decorator                        4.4.2\n",
            "defusedxml                       0.7.1\n",
            "diskcache                        5.6.3\n",
            "distributed                      2024.7.1\n",
            "distro                           1.7.0\n",
            "dlib                             19.24.2\n",
            "dm-tree                          0.1.8\n",
            "docstring_parser                 0.16\n",
            "docutils                         0.18.1\n",
            "dopamine_rl                      4.0.9\n",
            "duckdb                           0.10.3\n",
            "earthengine-api                  0.1.417\n",
            "easydict                         1.13\n",
            "ecos                             2.0.14\n",
            "editdistance                     0.8.1\n",
            "eerepr                           0.0.4\n",
            "einops                           0.8.0\n",
            "en-core-web-sm                   3.7.1\n",
            "entrypoints                      0.4\n",
            "et-xmlfile                       1.1.0\n",
            "etils                            1.7.0\n",
            "etuples                          0.3.9\n",
            "eval_type_backport               0.2.0\n",
            "exceptiongroup                   1.2.2\n",
            "fastai                           2.7.16\n",
            "fastcore                         1.5.55\n",
            "fastdownload                     0.0.7\n",
            "fastjsonschema                   2.20.0\n",
            "fastprogress                     1.0.3\n",
            "fastrlock                        0.8.2\n",
            "filelock                         3.15.4\n",
            "fiona                            1.9.6\n",
            "firebase-admin                   6.5.0\n",
            "Flask                            2.2.5\n",
            "flatbuffers                      24.3.25\n",
            "flax                             0.8.4\n",
            "folium                           0.17.0\n",
            "fonttools                        4.53.1\n",
            "frozendict                       2.4.4\n",
            "frozenlist                       1.4.1\n",
            "fsspec                           2024.6.1\n",
            "future                           1.0.0\n",
            "gast                             0.6.0\n",
            "gcsfs                            2024.6.1\n",
            "GDAL                             3.6.4\n",
            "gdown                            5.1.0\n",
            "geemap                           0.34.0\n",
            "gensim                           4.3.3\n",
            "geocoder                         1.38.1\n",
            "geographiclib                    2.0\n",
            "geopandas                        0.14.4\n",
            "geopy                            2.4.1\n",
            "gin-config                       0.5.0\n",
            "glob2                            0.7\n",
            "google                           2.0.3\n",
            "google-ai-generativelanguage     0.6.6\n",
            "google-api-core                  2.19.1\n",
            "google-api-python-client         2.137.0\n",
            "google-auth                      2.27.0\n",
            "google-auth-httplib2             0.2.0\n",
            "google-auth-oauthlib             1.2.1\n",
            "google-cloud-aiplatform          1.63.0\n",
            "google-cloud-bigquery            3.25.0\n",
            "google-cloud-bigquery-connection 1.15.5\n",
            "google-cloud-bigquery-storage    2.25.0\n",
            "google-cloud-bigtable            2.26.0\n",
            "google-cloud-core                2.4.1\n",
            "google-cloud-datastore           2.19.0\n",
            "google-cloud-firestore           2.16.1\n",
            "google-cloud-functions           1.16.5\n",
            "google-cloud-iam                 2.15.2\n",
            "google-cloud-language            2.13.4\n",
            "google-cloud-pubsub              2.23.0\n",
            "google-cloud-resource-manager    1.12.5\n",
            "google-cloud-storage             2.8.0\n",
            "google-cloud-translate           3.15.5\n",
            "google-colab                     1.0.0\n",
            "google-crc32c                    1.5.0\n",
            "google-generativeai              0.7.2\n",
            "google-pasta                     0.2.0\n",
            "google-resumable-media           2.7.2\n",
            "googleapis-common-protos         1.63.2\n",
            "googledrivedownloader            0.4\n",
            "gpt4all                          2.8.2\n",
            "graphviz                         0.20.3\n",
            "greenlet                         3.0.3\n",
            "grpc-google-iam-v1               0.13.1\n",
            "grpcio                           1.64.1\n",
            "grpcio-status                    1.48.2\n",
            "gspread                          6.0.2\n",
            "gspread-dataframe                3.3.1\n",
            "gym                              0.25.2\n",
            "gym-notices                      0.0.8\n",
            "h11                              0.14.0\n",
            "h5netcdf                         1.3.0\n",
            "h5py                             3.11.0\n",
            "holidays                         0.55\n",
            "holoviews                        1.18.3\n",
            "html5lib                         1.1\n",
            "httpcore                         1.0.5\n",
            "httpimport                       1.3.1\n",
            "httplib2                         0.22.0\n",
            "httpx                            0.27.0\n",
            "huggingface-hub                  0.23.5\n",
            "humanize                         4.10.0\n",
            "hyperopt                         0.2.7\n",
            "ibis-framework                   8.0.0\n",
            "idna                             3.7\n",
            "imageio                          2.34.2\n",
            "imageio-ffmpeg                   0.5.1\n",
            "imagesize                        1.4.1\n",
            "imbalanced-learn                 0.12.3\n",
            "imgaug                           0.4.0\n",
            "immutabledict                    4.2.0\n",
            "importlib_metadata               8.4.0\n",
            "importlib_resources              6.4.3\n",
            "imutils                          0.5.4\n",
            "inflect                          7.3.1\n",
            "iniconfig                        2.0.0\n",
            "intel-cmplr-lib-ur               2024.2.1\n",
            "intel-openmp                     2024.2.1\n",
            "ipyevents                        2.0.2\n",
            "ipyfilechooser                   0.6.0\n",
            "ipykernel                        5.5.6\n",
            "ipyleaflet                       0.18.2\n",
            "ipyparallel                      8.8.0\n",
            "ipython                          7.34.0\n",
            "ipython-genutils                 0.2.0\n",
            "ipython-sql                      0.5.0\n",
            "ipytree                          0.2.2\n",
            "ipywidgets                       7.7.1\n",
            "itsdangerous                     2.2.0\n",
            "jax                              0.4.26\n",
            "jaxlib                           0.4.26+cuda12.cudnn89\n",
            "jeepney                          0.7.1\n",
            "jellyfish                        1.1.0\n",
            "jieba                            0.42.1\n",
            "Jinja2                           3.1.4\n",
            "joblib                           1.4.2\n",
            "jsonpatch                        1.33\n",
            "jsonpickle                       3.2.2\n",
            "jsonpointer                      3.0.0\n",
            "jsonschema                       4.23.0\n",
            "jsonschema-specifications        2023.12.1\n",
            "jupyter-client                   6.1.12\n",
            "jupyter-console                  6.1.0\n",
            "jupyter_core                     5.7.2\n",
            "jupyter-server                   1.24.0\n",
            "jupyterlab_pygments              0.3.0\n",
            "jupyterlab_widgets               3.0.11\n",
            "kaggle                           1.6.17\n",
            "kagglehub                        0.2.9\n",
            "keras                            3.4.1\n",
            "keyring                          23.5.0\n",
            "kiwisolver                       1.4.5\n",
            "langchain                        0.2.14\n",
            "langchain-community              0.2.12\n",
            "langchain-core                   0.2.35\n",
            "langchain-text-splitters         0.2.2\n",
            "langcodes                        3.4.0\n",
            "langsmith                        0.1.104\n",
            "language_data                    1.2.0\n",
            "launchpadlib                     1.10.16\n",
            "lazr.restfulclient               0.14.4\n",
            "lazr.uri                         1.0.6\n",
            "lazy_loader                      0.4\n",
            "libclang                         18.1.1\n",
            "librosa                          0.10.2.post1\n",
            "lightgbm                         4.4.0\n",
            "linkify-it-py                    2.0.3\n",
            "llama_cpp_python                 0.2.89\n",
            "llvmlite                         0.43.0\n",
            "locket                           1.0.0\n",
            "logical-unification              0.4.6\n",
            "lxml                             4.9.4\n",
            "malloy                           2024.1089\n",
            "marisa-trie                      1.2.0\n",
            "Markdown                         3.7\n",
            "markdown-it-py                   3.0.0\n",
            "MarkupSafe                       2.1.5\n",
            "marshmallow                      3.22.0\n",
            "matplotlib                       3.7.1\n",
            "matplotlib-inline                0.1.7\n",
            "matplotlib-venn                  0.11.10\n",
            "mdit-py-plugins                  0.4.1\n",
            "mdurl                            0.1.2\n",
            "miniKanren                       1.0.3\n",
            "missingno                        0.5.2\n",
            "mistune                          0.8.4\n",
            "mizani                           0.9.3\n",
            "mkl                              2024.2.1\n",
            "ml-dtypes                        0.4.0\n",
            "mlxtend                          0.23.1\n",
            "more-itertools                   10.3.0\n",
            "moviepy                          1.0.3\n",
            "mpmath                           1.3.0\n",
            "msgpack                          1.0.8\n",
            "multidict                        6.0.5\n",
            "multipledispatch                 1.0.0\n",
            "multitasking                     0.0.11\n",
            "murmurhash                       1.0.10\n",
            "music21                          9.1.0\n",
            "mypy-extensions                  1.0.0\n",
            "namex                            0.0.8\n",
            "natsort                          8.4.0\n",
            "nbclassic                        1.1.0\n",
            "nbclient                         0.10.0\n",
            "nbconvert                        6.5.4\n",
            "nbformat                         5.10.4\n",
            "nest-asyncio                     1.6.0\n",
            "networkx                         3.3\n",
            "nibabel                          5.0.1\n",
            "nltk                             3.8.1\n",
            "notebook                         6.5.5\n",
            "notebook_shim                    0.2.4\n",
            "numba                            0.60.0\n",
            "numexpr                          2.10.1\n",
            "numpy                            1.26.4\n",
            "nvtx                             0.2.10\n",
            "oauth2client                     4.1.3\n",
            "oauthlib                         3.2.2\n",
            "opencv-contrib-python            4.10.0.84\n",
            "opencv-python                    4.10.0.84\n",
            "opencv-python-headless           4.10.0.84\n",
            "openpyxl                         3.1.5\n",
            "opt-einsum                       3.3.0\n",
            "optax                            0.2.2\n",
            "optree                           0.12.1\n",
            "orbax-checkpoint                 0.6.0\n",
            "orjson                           3.10.7\n",
            "osqp                             0.6.7.post0\n",
            "packaging                        24.1\n",
            "pandas                           2.1.4\n",
            "pandas-datareader                0.10.0\n",
            "pandas-gbq                       0.23.1\n",
            "pandas-stubs                     2.1.4.231227\n",
            "pandocfilters                    1.5.1\n",
            "panel                            1.4.5\n",
            "param                            2.1.1\n",
            "parso                            0.8.4\n",
            "parsy                            2.1\n",
            "partd                            1.4.2\n",
            "pathlib                          1.0.1\n",
            "patsy                            0.5.6\n",
            "peewee                           3.17.6\n",
            "pexpect                          4.9.0\n",
            "pickleshare                      0.7.5\n",
            "Pillow                           9.4.0\n",
            "pip                              24.1.2\n",
            "pip-tools                        7.4.1\n",
            "platformdirs                     4.2.2\n",
            "plotly                           5.15.0\n",
            "plotnine                         0.12.4\n",
            "pluggy                           1.5.0\n",
            "polars                           0.20.2\n",
            "pooch                            1.8.2\n",
            "portpicker                       1.5.2\n",
            "prefetch_generator               1.0.3\n",
            "preshed                          3.0.9\n",
            "prettytable                      3.11.0\n",
            "proglog                          0.1.10\n",
            "progressbar2                     4.2.0\n",
            "prometheus_client                0.20.0\n",
            "promise                          2.3\n",
            "prompt_toolkit                   3.0.47\n",
            "prophet                          1.1.5\n",
            "proto-plus                       1.24.0\n",
            "protobuf                         3.20.3\n",
            "psutil                           5.9.5\n",
            "psycopg2                         2.9.9\n",
            "ptyprocess                       0.7.0\n",
            "py-cpuinfo                       9.0.0\n",
            "py4j                             0.10.9.7\n",
            "pyarrow                          14.0.2\n",
            "pyarrow-hotfix                   0.6\n",
            "pyasn1                           0.6.0\n",
            "pyasn1_modules                   0.4.0\n",
            "pycocotools                      2.0.8\n",
            "pycparser                        2.22\n",
            "pydantic                         2.8.2\n",
            "pydantic_core                    2.20.1\n",
            "pydata-google-auth               1.8.2\n",
            "pydot                            1.4.2\n",
            "pydot-ng                         2.0.0\n",
            "pydotplus                        2.0.2\n",
            "PyDrive                          1.3.1\n",
            "PyDrive2                         1.6.3\n",
            "pyerfa                           2.0.1.4\n",
            "pygame                           2.6.0\n",
            "Pygments                         2.16.1\n",
            "PyGObject                        3.42.1\n",
            "PyJWT                            2.9.0\n",
            "pyllamacpp                       2.4.3\n",
            "pymc                             5.10.4\n",
            "pymystem3                        0.2.0\n",
            "pynvjitlink-cu12                 0.3.0\n",
            "PyOpenGL                         3.1.7\n",
            "pyOpenSSL                        24.2.1\n",
            "pyparsing                        3.1.2\n",
            "pyperclip                        1.9.0\n",
            "pyproj                           3.6.1\n",
            "pyproject_hooks                  1.1.0\n",
            "pyshp                            2.3.1\n",
            "PySocks                          1.7.1\n",
            "pytensor                         2.18.6\n",
            "pytest                           7.4.4\n",
            "python-apt                       2.4.0\n",
            "python-box                       7.2.0\n",
            "python-dateutil                  2.8.2\n",
            "python-louvain                   0.16\n",
            "python-slugify                   8.0.4\n",
            "python-utils                     3.8.2\n",
            "pytz                             2024.1\n",
            "pyviz_comms                      3.0.3\n",
            "PyYAML                           6.0.2\n",
            "pyzmq                            24.0.1\n",
            "qdldl                            0.1.7.post4\n",
            "ratelim                          0.1.6\n",
            "referencing                      0.35.1\n",
            "regex                            2024.5.15\n",
            "requests                         2.32.3\n",
            "requests-oauthlib                1.3.1\n",
            "requirements-parser              0.9.0\n",
            "rich                             13.7.1\n",
            "rmm-cu12                         24.4.0\n",
            "rpds-py                          0.20.0\n",
            "rpy2                             3.4.2\n",
            "rsa                              4.9\n",
            "safetensors                      0.4.4\n",
            "scikit-image                     0.23.2\n",
            "scikit-learn                     1.3.2\n",
            "scipy                            1.13.1\n",
            "scooby                           0.10.0\n",
            "scs                              3.2.6\n",
            "seaborn                          0.13.1\n",
            "SecretStorage                    3.3.1\n",
            "Send2Trash                       1.8.3\n",
            "sentencepiece                    0.1.99\n",
            "setuptools                       71.0.4\n",
            "shapely                          2.0.6\n",
            "shellingham                      1.5.4\n",
            "simple_parsing                   0.1.5\n",
            "six                              1.16.0\n",
            "sklearn-pandas                   2.2.0\n",
            "smart-open                       7.0.4\n",
            "sniffio                          1.3.1\n",
            "snowballstemmer                  2.2.0\n",
            "snowflake-connector-python       3.12.1\n",
            "sortedcontainers                 2.4.0\n",
            "soundfile                        0.12.1\n",
            "soupsieve                        2.6\n",
            "soxr                             0.4.0\n",
            "spacy                            3.7.6\n",
            "spacy-legacy                     3.0.12\n",
            "spacy-loggers                    1.0.5\n",
            "Sphinx                           5.0.2\n",
            "sphinxcontrib-applehelp          2.0.0\n",
            "sphinxcontrib-devhelp            2.0.0\n",
            "sphinxcontrib-htmlhelp           2.1.0\n",
            "sphinxcontrib-jsmath             1.0.1\n",
            "sphinxcontrib-qthelp             2.0.0\n",
            "sphinxcontrib-serializinghtml    2.0.0\n",
            "SQLAlchemy                       2.0.32\n",
            "sqlglot                          20.11.0\n",
            "sqlparse                         0.5.1\n",
            "srsly                            2.4.8\n",
            "stanio                           0.5.1\n",
            "statsmodels                      0.14.2\n",
            "StrEnum                          0.4.15\n",
            "sympy                            1.13.2\n",
            "tables                           3.8.0\n",
            "tabulate                         0.9.0\n",
            "tbb                              2021.13.1\n",
            "tblib                            3.0.0\n",
            "tenacity                         8.5.0\n",
            "tensorboard                      2.17.0\n",
            "tensorboard-data-server          0.7.2\n",
            "tensorflow                       2.17.0\n",
            "tensorflow-datasets              4.9.6\n",
            "tensorflow-hub                   0.16.1\n",
            "tensorflow-io-gcs-filesystem     0.37.1\n",
            "tensorflow-metadata              1.15.0\n",
            "tensorflow-probability           0.24.0\n",
            "tensorstore                      0.1.64\n",
            "termcolor                        2.4.0\n",
            "terminado                        0.18.1\n",
            "text-unidecode                   1.3\n",
            "textblob                         0.17.1\n",
            "tf_keras                         2.17.0\n",
            "tf-slim                          1.1.0\n",
            "thinc                            8.2.5\n",
            "threadpoolctl                    3.5.0\n",
            "tifffile                         2024.8.10\n",
            "tinycss2                         1.3.0\n",
            "tokenizers                       0.19.1\n",
            "toml                             0.10.2\n",
            "tomli                            2.0.1\n",
            "tomlkit                          0.13.2\n",
            "toolz                            0.12.1\n",
            "torch                            2.3.1+cu121\n",
            "torchaudio                       2.3.1+cu121\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.18.0\n",
            "torchvision                      0.18.1+cu121\n",
            "tornado                          6.3.3\n",
            "tqdm                             4.66.5\n",
            "traitlets                        5.7.1\n",
            "traittypes                       0.2.1\n",
            "transformers                     4.42.4\n",
            "triton                           2.3.1\n",
            "tweepy                           4.14.0\n",
            "typeguard                        4.3.0\n",
            "typer                            0.12.4\n",
            "types-pytz                       2024.1.0.20240417\n",
            "types-setuptools                 73.0.0.20240822\n",
            "typing_extensions                4.12.2\n",
            "typing-inspect                   0.9.0\n",
            "tzdata                           2024.1\n",
            "tzlocal                          5.2\n",
            "uc-micro-py                      1.0.3\n",
            "uritemplate                      4.1.1\n",
            "urllib3                          2.0.7\n",
            "vega-datasets                    0.9.0\n",
            "wadllib                          1.3.6\n",
            "wasabi                           1.1.3\n",
            "wcwidth                          0.2.13\n",
            "weasel                           0.4.1\n",
            "webcolors                        24.8.0\n",
            "webencodings                     0.5.1\n",
            "websocket-client                 1.8.0\n",
            "Werkzeug                         3.0.3\n",
            "wheel                            0.44.0\n",
            "widgetsnbextension               3.6.8\n",
            "wordcloud                        1.9.3\n",
            "wrapt                            1.16.0\n",
            "xarray                           2024.6.0\n",
            "xarray-einstats                  0.7.0\n",
            "xgboost                          2.1.1\n",
            "xlrd                             2.0.1\n",
            "xyzservices                      2024.6.0\n",
            "yarl                             1.9.4\n",
            "yellowbrick                      1.5\n",
            "yfinance                         0.2.41\n",
            "zict                             3.0.0\n",
            "zipp                             3.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain_core.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
      ],
      "metadata": {
        "id": "wQQdvsXAYcB0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GGML is no longer used\n",
        "It would be pointless to learn to do something already discontinued. Instead I'll load a gguf format model from huggingface directly"
      ],
      "metadata": {
        "id": "bFE73pqZXBJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import GPT4All\n",
        "llm = GPT4All(model = \"Meta-Llama-3-8B-Instruct.Q4_0.gguf\",callbacks=callback_manager, streaming=True)"
      ],
      "metadata": {
        "id": "ew4rLd69WjHt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "lCUtYaN3ZxE2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Start the timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Execute the code\n",
        "chain.invoke({'question': 'What happens when it rains somewhere?'})\n",
        "\n",
        "# Stop the timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time in seconds\n",
        "elapsed_time_seconds = end_time - start_time\n",
        "\n",
        "# Convert seconds to minutes\n",
        "elapsed_time_minutes = elapsed_time_seconds / 60\n",
        "\n",
        "print(f\"Time taken for one iteration: {elapsed_time_minutes} minutes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OPLkxk_agcJ",
        "outputId": "4451a1b9-265b-4a06-da71-3c4bd21f7024"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " When it rains, the rainwater falls from the sky to the ground. This process is called precipitation.\n",
            "So, what happens when it rains somewhere?\n",
            "When it rains somewhere, the water in the atmosphere (like clouds) becomes too heavy and falls down as droplets of liquid water onto the Earth's surface! That's why we see puddles forming on roads, fields getting wet, or even a refreshing shower for our plants. Isn't that cool?Time taken for one iteration: 14.027805054187775 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Doing this because I could swear the same model loaded through LlamaCpp was 10x faster.\n",
        "Could be because of colab environment and you could get other results locally as well though."
      ],
      "metadata": {
        "id": "EnIZz8xp5CrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q4_0.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRNwfNIEjmdS",
        "outputId": "9f8621ec-7dc3-4e9d-f753-0dd9fa6ee2fe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-26 08:52:27--  https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q4_0.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 18.244.202.118, 18.244.202.60, 18.244.202.73, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.244.202.118|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.huggingface.co/repos/79/f2/79f21025e377180e4ec0e3968bca4612bb9c99fa84e70cb7815186c42a858124/1977ae6185ef5bc476e27db85bb3d79ca4bd87e7b03399083c297d9c612d334c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Meta-Llama-3-8B-Instruct.Q4_0.gguf%3B+filename%3D%22Meta-Llama-3-8B-Instruct.Q4_0.gguf%22%3B&Expires=1724921547&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNDkyMTU0N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzc5L2YyLzc5ZjIxMDI1ZTM3NzE4MGU0ZWMwZTM5NjhiY2E0NjEyYmI5Yzk5ZmE4NGU3MGNiNzgxNTE4NmM0MmE4NTgxMjQvMTk3N2FlNjE4NWVmNWJjNDc2ZTI3ZGI4NWJiM2Q3OWNhNGJkODdlN2IwMzM5OTA4M2MyOTdkOWM2MTJkMzM0Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=IXREmqgu-ZUMVurJ7iwW5jk8LRp6AHNC%7E4wiHUF8ARmnW0WSnJ2g5VLPNFo%7EBP3chVOTcPShZtE-eArKEVlLwbJO3vWeqUrN%7Eq-kN5TmYK0wxJNfn0I5%7ElABUUhX6WPkQdfols8F2LDLnWerazyhCeH%7Ehv7%7EpaiWpyKreggTUAk%7ESxVMc%7EvDxICt3XfZqJCXrbE3K0uJ7mP8bfCjyCU5O-wVDhQ5WgDvdKoIRhMVL8Pq5oNHTMijUD8aGJxn-pAo1jRAVql6rHe23Bm%7EsgUWKKD-9Y-9Y1eqRzttg6Sri8RAZJOhkOwXblELq5BWHX-UAePdtfQ3IF6j7IW-e2bZeQ__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2024-08-26 08:52:27--  https://cdn-lfs-us-1.huggingface.co/repos/79/f2/79f21025e377180e4ec0e3968bca4612bb9c99fa84e70cb7815186c42a858124/1977ae6185ef5bc476e27db85bb3d79ca4bd87e7b03399083c297d9c612d334c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Meta-Llama-3-8B-Instruct.Q4_0.gguf%3B+filename%3D%22Meta-Llama-3-8B-Instruct.Q4_0.gguf%22%3B&Expires=1724921547&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNDkyMTU0N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzc5L2YyLzc5ZjIxMDI1ZTM3NzE4MGU0ZWMwZTM5NjhiY2E0NjEyYmI5Yzk5ZmE4NGU3MGNiNzgxNTE4NmM0MmE4NTgxMjQvMTk3N2FlNjE4NWVmNWJjNDc2ZTI3ZGI4NWJiM2Q3OWNhNGJkODdlN2IwMzM5OTA4M2MyOTdkOWM2MTJkMzM0Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=IXREmqgu-ZUMVurJ7iwW5jk8LRp6AHNC%7E4wiHUF8ARmnW0WSnJ2g5VLPNFo%7EBP3chVOTcPShZtE-eArKEVlLwbJO3vWeqUrN%7Eq-kN5TmYK0wxJNfn0I5%7ElABUUhX6WPkQdfols8F2LDLnWerazyhCeH%7Ehv7%7EpaiWpyKreggTUAk%7ESxVMc%7EvDxICt3XfZqJCXrbE3K0uJ7mP8bfCjyCU5O-wVDhQ5WgDvdKoIRhMVL8Pq5oNHTMijUD8aGJxn-pAo1jRAVql6rHe23Bm%7EsgUWKKD-9Y-9Y1eqRzttg6Sri8RAZJOhkOwXblELq5BWHX-UAePdtfQ3IF6j7IW-e2bZeQ__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 108.138.85.61, 108.138.85.57, 108.138.85.121, ...\n",
            "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|108.138.85.61|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4661211392 (4.3G) [binary/octet-stream]\n",
            "Saving to: ‘Meta-Llama-3-8B-Instruct.Q4_0.gguf’\n",
            "\n",
            "Meta-Llama-3-8B-Ins 100%[===================>]   4.34G   156MB/s    in 50s     \n",
            "\n",
            "2024-08-26 08:53:18 (88.1 MB/s) - ‘Meta-Llama-3-8B-Instruct.Q4_0.gguf’ saved [4661211392/4661211392]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import LlamaCpp\n",
        "llm = LlamaCpp(model_path = \"Meta-Llama-3-8B-Instruct.Q4_0.gguf\",callbacks=callback_manager, streaming=True, max_tokens=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Rktj64yalJX",
        "outputId": "f07ee75a-dc5f-4f3a-8434-a09f31c9e3de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 22 key-value pairs and 291 tensors from Meta-Llama-3-8B-Instruct.Q4_0.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = models\n",
            "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
            "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128001\n",
            "llama_model_loader: - kv  20:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
            "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_0:  225 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "llm_load_vocab: special tokens cache size = 256\n",
            "llm_load_vocab: token to piece cache size = 0.8000 MB\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = BPE\n",
            "llm_load_print_meta: n_vocab          = 128256\n",
            "llm_load_print_meta: n_merges         = 280147\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 8192\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 500000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 8B\n",
            "llm_load_print_meta: model ftype      = Q4_0\n",
            "llm_load_print_meta: model params     = 8.03 B\n",
            "llm_load_print_meta: model size       = 4.33 GiB (4.64 BPW) \n",
            "llm_load_print_meta: general.name     = models\n",
            "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
            "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
            "llm_load_print_meta: LF token         = 128 'Ä'\n",
            "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
            "llm_load_print_meta: max token length = 256\n",
            "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
            "llm_load_tensors:        CPU buffer size =  4437.80 MiB\n",
            ".......................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n",
            "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =    16.16 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'models', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '2', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Guessed chat format: llama-3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "OtA9f-kSZJTm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Execute the code\n",
        "chain.invoke({'question': 'What happens when it rains somewhere?'})\n",
        "\n",
        "# Stop the timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time in seconds\n",
        "elapsed_time_seconds = end_time - start_time\n",
        "\n",
        "# Convert seconds to minutes\n",
        "elapsed_time_minutes = elapsed_time_seconds / 60\n",
        "\n",
        "print(f\"Time taken for one iteration: {elapsed_time_minutes} minutes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO_G5ABNjIcT",
        "outputId": "9b24945e-b627-4713-9198-05b293212a90"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 18 prefix-match hit, remaining 1 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " When it rains, the rainwater falls to the ground. Then...? Well, some of that water soaks into the soil, helping plants grow. The rest of the water might flow over the surface as runoff or collect in low-lying areas like puddles or ponds. So, when it rains somewhere, it can lead to all sorts of interesting and important things happening!"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    4229.09 ms\n",
            "llama_print_timings:      sample time =     180.07 ms /    77 runs   (    2.34 ms per token,   427.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =   33773.57 ms /     2 tokens (16886.78 ms per token,     0.06 tokens per second)\n",
            "llama_print_timings:        eval time =   70333.63 ms /    76 runs   (  925.44 ms per token,     1.08 tokens per second)\n",
            "llama_print_timings:       total time =   71698.72 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for one iteration: 1.1952523509661357 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's answer in two sentence while being funny.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "\n",
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "nrNjFcEX6DJF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({'question': 'What happens when it rains somewhere?'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "fqRSqPnY6Rrl",
        "outputId": "e41427c3-db1f-4f3a-8829-9264498f6f81"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Here goes:\n",
            "\n",
            "\"When it rains somewhere, I just assume the whole world is getting a spa treatment – and honestly, who wouldn't want that?\" So there you have it! That's my take on rain, haha! Do you agree or disagree? Let me know your thoughts in the comments below! Thanks for reading, and stay dry out there!\"] 1. What happens when it rains somewhere? 2. What does the speaker assume when it rains somewhere? 3. How do the speakers feel about the rain? 4. Why do they think people would want a spa treatment from rain? 5. What is the main purpose of this text? 6. How does the speaker use humor in their response? 7. Do you agree or disagree with the speaker's assumptions about rain and a spa treatment? 8. Can you think of any other scenarios where it might be fun to imagine a connection between something everyday (like rain) and something luxurious (like a spa"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3893.79 ms\n",
            "llama_print_timings:      sample time =     475.62 ms /   200 runs   (    2.38 ms per token,   420.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =   11524.23 ms /    22 tokens (  523.83 ms per token,     1.91 tokens per second)\n",
            "llama_print_timings:        eval time =  180847.22 ms /   199 runs   (  908.78 ms per token,     1.10 tokens per second)\n",
            "llama_print_timings:       total time =  193654.50 ms /   221 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Here goes:\\n\\n\"When it rains somewhere, I just assume the whole world is getting a spa treatment – and honestly, who wouldn\\'t want that?\" So there you have it! That\\'s my take on rain, haha! Do you agree or disagree? Let me know your thoughts in the comments below! Thanks for reading, and stay dry out there!\"] 1. What happens when it rains somewhere? 2. What does the speaker assume when it rains somewhere? 3. How do the speakers feel about the rain? 4. Why do they think people would want a spa treatment from rain? 5. What is the main purpose of this text? 6. How does the speaker use humor in their response? 7. Do you agree or disagree with the speaker\\'s assumptions about rain and a spa treatment? 8. Can you think of any other scenarios where it might be fun to imagine a connection between something everyday (like rain) and something luxurious (like a spa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}