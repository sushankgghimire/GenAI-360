{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1jf0yXL2708Q"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_community llama-cpp-python -q\n",
        "clear_output()\n",
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su86rOtE8dYs",
        "outputId": "ee8099a9-a9dd-43ea-ea1d-59bee6fadf7a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                          Version\n",
            "-------------------------------- ---------------------\n",
            "absl-py                          1.4.0\n",
            "accelerate                       0.32.1\n",
            "aiohappyeyeballs                 2.4.0\n",
            "aiohttp                          3.10.5\n",
            "aiosignal                        1.3.1\n",
            "alabaster                        0.7.16\n",
            "albucore                         0.0.13\n",
            "albumentations                   1.4.14\n",
            "altair                           4.2.2\n",
            "annotated-types                  0.7.0\n",
            "anyio                            3.7.1\n",
            "argon2-cffi                      23.1.0\n",
            "argon2-cffi-bindings             21.2.0\n",
            "array_record                     0.5.1\n",
            "arviz                            0.18.0\n",
            "asn1crypto                       1.5.1\n",
            "astropy                          6.1.2\n",
            "astropy-iers-data                0.2024.8.19.0.32.16\n",
            "astunparse                       1.6.3\n",
            "async-timeout                    4.0.3\n",
            "atpublic                         4.1.0\n",
            "attrs                            24.2.0\n",
            "audioread                        3.0.1\n",
            "autograd                         1.6.2\n",
            "babel                            2.16.0\n",
            "backcall                         0.2.0\n",
            "beautifulsoup4                   4.12.3\n",
            "bidict                           0.23.1\n",
            "bigframes                        1.15.0\n",
            "bleach                           6.1.0\n",
            "blinker                          1.4\n",
            "blis                             0.7.11\n",
            "blosc2                           2.0.0\n",
            "bokeh                            3.4.3\n",
            "bqplot                           0.12.43\n",
            "branca                           0.7.2\n",
            "build                            1.2.1\n",
            "CacheControl                     0.14.0\n",
            "cachetools                       5.5.0\n",
            "catalogue                        2.0.10\n",
            "certifi                          2024.7.4\n",
            "cffi                             1.17.0\n",
            "chardet                          5.2.0\n",
            "charset-normalizer               3.3.2\n",
            "chex                             0.1.86\n",
            "clarabel                         0.9.0\n",
            "click                            8.1.7\n",
            "click-plugins                    1.1.1\n",
            "cligj                            0.7.2\n",
            "cloudpathlib                     0.18.1\n",
            "cloudpickle                      2.2.1\n",
            "cmake                            3.30.2\n",
            "cmdstanpy                        1.2.4\n",
            "colorcet                         3.1.0\n",
            "colorlover                       0.3.0\n",
            "colour                           0.1.5\n",
            "community                        1.0.0b1\n",
            "confection                       0.1.5\n",
            "cons                             0.4.6\n",
            "contextlib2                      21.6.0\n",
            "contourpy                        1.2.1\n",
            "cryptography                     43.0.0\n",
            "cuda-python                      12.2.1\n",
            "cudf-cu12                        24.4.1\n",
            "cufflinks                        0.17.3\n",
            "cupy-cuda12x                     12.2.0\n",
            "cvxopt                           1.3.2\n",
            "cvxpy                            1.5.3\n",
            "cycler                           0.12.1\n",
            "cymem                            2.0.8\n",
            "Cython                           3.0.11\n",
            "dask                             2024.7.1\n",
            "dataclasses-json                 0.6.7\n",
            "datascience                      0.17.6\n",
            "db-dtypes                        1.3.0\n",
            "dbus-python                      1.2.18\n",
            "debugpy                          1.6.6\n",
            "decorator                        4.4.2\n",
            "defusedxml                       0.7.1\n",
            "diskcache                        5.6.3\n",
            "distributed                      2024.7.1\n",
            "distro                           1.7.0\n",
            "dlib                             19.24.2\n",
            "dm-tree                          0.1.8\n",
            "docstring_parser                 0.16\n",
            "docutils                         0.18.1\n",
            "dopamine_rl                      4.0.9\n",
            "duckdb                           0.10.3\n",
            "earthengine-api                  0.1.417\n",
            "easydict                         1.13\n",
            "ecos                             2.0.14\n",
            "editdistance                     0.8.1\n",
            "eerepr                           0.0.4\n",
            "einops                           0.8.0\n",
            "en-core-web-sm                   3.7.1\n",
            "entrypoints                      0.4\n",
            "et-xmlfile                       1.1.0\n",
            "etils                            1.7.0\n",
            "etuples                          0.3.9\n",
            "eval_type_backport               0.2.0\n",
            "exceptiongroup                   1.2.2\n",
            "fastai                           2.7.16\n",
            "fastcore                         1.5.55\n",
            "fastdownload                     0.0.7\n",
            "fastjsonschema                   2.20.0\n",
            "fastprogress                     1.0.3\n",
            "fastrlock                        0.8.2\n",
            "filelock                         3.15.4\n",
            "fiona                            1.9.6\n",
            "firebase-admin                   6.5.0\n",
            "Flask                            2.2.5\n",
            "flatbuffers                      24.3.25\n",
            "flax                             0.8.4\n",
            "folium                           0.17.0\n",
            "fonttools                        4.53.1\n",
            "frozendict                       2.4.4\n",
            "frozenlist                       1.4.1\n",
            "fsspec                           2024.6.1\n",
            "future                           1.0.0\n",
            "gast                             0.6.0\n",
            "gcsfs                            2024.6.1\n",
            "GDAL                             3.6.4\n",
            "gdown                            5.1.0\n",
            "geemap                           0.34.0\n",
            "gensim                           4.3.3\n",
            "geocoder                         1.38.1\n",
            "geographiclib                    2.0\n",
            "geopandas                        0.14.4\n",
            "geopy                            2.4.1\n",
            "gin-config                       0.5.0\n",
            "glob2                            0.7\n",
            "google                           2.0.3\n",
            "google-ai-generativelanguage     0.6.6\n",
            "google-api-core                  2.19.1\n",
            "google-api-python-client         2.137.0\n",
            "google-auth                      2.27.0\n",
            "google-auth-httplib2             0.2.0\n",
            "google-auth-oauthlib             1.2.1\n",
            "google-cloud-aiplatform          1.63.0\n",
            "google-cloud-bigquery            3.25.0\n",
            "google-cloud-bigquery-connection 1.15.5\n",
            "google-cloud-bigquery-storage    2.25.0\n",
            "google-cloud-bigtable            2.26.0\n",
            "google-cloud-core                2.4.1\n",
            "google-cloud-datastore           2.19.0\n",
            "google-cloud-firestore           2.16.1\n",
            "google-cloud-functions           1.16.5\n",
            "google-cloud-iam                 2.15.2\n",
            "google-cloud-language            2.13.4\n",
            "google-cloud-pubsub              2.23.0\n",
            "google-cloud-resource-manager    1.12.5\n",
            "google-cloud-storage             2.8.0\n",
            "google-cloud-translate           3.15.5\n",
            "google-colab                     1.0.0\n",
            "google-crc32c                    1.5.0\n",
            "google-generativeai              0.7.2\n",
            "google-pasta                     0.2.0\n",
            "google-resumable-media           2.7.2\n",
            "googleapis-common-protos         1.63.2\n",
            "googledrivedownloader            0.4\n",
            "graphviz                         0.20.3\n",
            "greenlet                         3.0.3\n",
            "grpc-google-iam-v1               0.13.1\n",
            "grpcio                           1.64.1\n",
            "grpcio-status                    1.48.2\n",
            "gspread                          6.0.2\n",
            "gspread-dataframe                3.3.1\n",
            "gym                              0.25.2\n",
            "gym-notices                      0.0.8\n",
            "h11                              0.14.0\n",
            "h5netcdf                         1.3.0\n",
            "h5py                             3.11.0\n",
            "holidays                         0.55\n",
            "holoviews                        1.18.3\n",
            "html5lib                         1.1\n",
            "httpcore                         1.0.5\n",
            "httpimport                       1.3.1\n",
            "httplib2                         0.22.0\n",
            "httpx                            0.27.0\n",
            "huggingface-hub                  0.23.5\n",
            "humanize                         4.10.0\n",
            "hyperopt                         0.2.7\n",
            "ibis-framework                   8.0.0\n",
            "idna                             3.7\n",
            "imageio                          2.34.2\n",
            "imageio-ffmpeg                   0.5.1\n",
            "imagesize                        1.4.1\n",
            "imbalanced-learn                 0.12.3\n",
            "imgaug                           0.4.0\n",
            "immutabledict                    4.2.0\n",
            "importlib_metadata               8.4.0\n",
            "importlib_resources              6.4.3\n",
            "imutils                          0.5.4\n",
            "inflect                          7.3.1\n",
            "iniconfig                        2.0.0\n",
            "intel-cmplr-lib-ur               2024.2.1\n",
            "intel-openmp                     2024.2.1\n",
            "ipyevents                        2.0.2\n",
            "ipyfilechooser                   0.6.0\n",
            "ipykernel                        5.5.6\n",
            "ipyleaflet                       0.18.2\n",
            "ipyparallel                      8.8.0\n",
            "ipython                          7.34.0\n",
            "ipython-genutils                 0.2.0\n",
            "ipython-sql                      0.5.0\n",
            "ipytree                          0.2.2\n",
            "ipywidgets                       7.7.1\n",
            "itsdangerous                     2.2.0\n",
            "jax                              0.4.26\n",
            "jaxlib                           0.4.26+cuda12.cudnn89\n",
            "jeepney                          0.7.1\n",
            "jellyfish                        1.1.0\n",
            "jieba                            0.42.1\n",
            "Jinja2                           3.1.4\n",
            "joblib                           1.4.2\n",
            "jsonpatch                        1.33\n",
            "jsonpickle                       3.2.2\n",
            "jsonpointer                      3.0.0\n",
            "jsonschema                       4.23.0\n",
            "jsonschema-specifications        2023.12.1\n",
            "jupyter-client                   6.1.12\n",
            "jupyter-console                  6.1.0\n",
            "jupyter_core                     5.7.2\n",
            "jupyter-server                   1.24.0\n",
            "jupyterlab_pygments              0.3.0\n",
            "jupyterlab_widgets               3.0.11\n",
            "kaggle                           1.6.17\n",
            "kagglehub                        0.2.9\n",
            "keras                            3.4.1\n",
            "keyring                          23.5.0\n",
            "kiwisolver                       1.4.5\n",
            "langchain                        0.2.14\n",
            "langchain-community              0.2.12\n",
            "langchain-core                   0.2.35\n",
            "langchain-text-splitters         0.2.2\n",
            "langcodes                        3.4.0\n",
            "langsmith                        0.1.104\n",
            "language_data                    1.2.0\n",
            "launchpadlib                     1.10.16\n",
            "lazr.restfulclient               0.14.4\n",
            "lazr.uri                         1.0.6\n",
            "lazy_loader                      0.4\n",
            "libclang                         18.1.1\n",
            "librosa                          0.10.2.post1\n",
            "lightgbm                         4.4.0\n",
            "linkify-it-py                    2.0.3\n",
            "llama_cpp_python                 0.2.89\n",
            "llvmlite                         0.43.0\n",
            "locket                           1.0.0\n",
            "logical-unification              0.4.6\n",
            "lxml                             4.9.4\n",
            "malloy                           2024.1089\n",
            "marisa-trie                      1.2.0\n",
            "Markdown                         3.7\n",
            "markdown-it-py                   3.0.0\n",
            "MarkupSafe                       2.1.5\n",
            "marshmallow                      3.22.0\n",
            "matplotlib                       3.7.1\n",
            "matplotlib-inline                0.1.7\n",
            "matplotlib-venn                  0.11.10\n",
            "mdit-py-plugins                  0.4.1\n",
            "mdurl                            0.1.2\n",
            "miniKanren                       1.0.3\n",
            "missingno                        0.5.2\n",
            "mistune                          0.8.4\n",
            "mizani                           0.9.3\n",
            "mkl                              2024.2.1\n",
            "ml-dtypes                        0.4.0\n",
            "mlxtend                          0.23.1\n",
            "more-itertools                   10.3.0\n",
            "moviepy                          1.0.3\n",
            "mpmath                           1.3.0\n",
            "msgpack                          1.0.8\n",
            "multidict                        6.0.5\n",
            "multipledispatch                 1.0.0\n",
            "multitasking                     0.0.11\n",
            "murmurhash                       1.0.10\n",
            "music21                          9.1.0\n",
            "mypy-extensions                  1.0.0\n",
            "namex                            0.0.8\n",
            "natsort                          8.4.0\n",
            "nbclassic                        1.1.0\n",
            "nbclient                         0.10.0\n",
            "nbconvert                        6.5.4\n",
            "nbformat                         5.10.4\n",
            "nest-asyncio                     1.6.0\n",
            "networkx                         3.3\n",
            "nibabel                          5.0.1\n",
            "nltk                             3.8.1\n",
            "notebook                         6.5.5\n",
            "notebook_shim                    0.2.4\n",
            "numba                            0.60.0\n",
            "numexpr                          2.10.1\n",
            "numpy                            1.26.4\n",
            "nvtx                             0.2.10\n",
            "oauth2client                     4.1.3\n",
            "oauthlib                         3.2.2\n",
            "opencv-contrib-python            4.10.0.84\n",
            "opencv-python                    4.10.0.84\n",
            "opencv-python-headless           4.10.0.84\n",
            "openpyxl                         3.1.5\n",
            "opt-einsum                       3.3.0\n",
            "optax                            0.2.2\n",
            "optree                           0.12.1\n",
            "orbax-checkpoint                 0.6.0\n",
            "orjson                           3.10.7\n",
            "osqp                             0.6.7.post0\n",
            "packaging                        24.1\n",
            "pandas                           2.1.4\n",
            "pandas-datareader                0.10.0\n",
            "pandas-gbq                       0.23.1\n",
            "pandas-stubs                     2.1.4.231227\n",
            "pandocfilters                    1.5.1\n",
            "panel                            1.4.5\n",
            "param                            2.1.1\n",
            "parso                            0.8.4\n",
            "parsy                            2.1\n",
            "partd                            1.4.2\n",
            "pathlib                          1.0.1\n",
            "patsy                            0.5.6\n",
            "peewee                           3.17.6\n",
            "pexpect                          4.9.0\n",
            "pickleshare                      0.7.5\n",
            "Pillow                           9.4.0\n",
            "pip                              24.1.2\n",
            "pip-tools                        7.4.1\n",
            "platformdirs                     4.2.2\n",
            "plotly                           5.15.0\n",
            "plotnine                         0.12.4\n",
            "pluggy                           1.5.0\n",
            "polars                           0.20.2\n",
            "pooch                            1.8.2\n",
            "portpicker                       1.5.2\n",
            "prefetch_generator               1.0.3\n",
            "preshed                          3.0.9\n",
            "prettytable                      3.11.0\n",
            "proglog                          0.1.10\n",
            "progressbar2                     4.2.0\n",
            "prometheus_client                0.20.0\n",
            "promise                          2.3\n",
            "prompt_toolkit                   3.0.47\n",
            "prophet                          1.1.5\n",
            "proto-plus                       1.24.0\n",
            "protobuf                         3.20.3\n",
            "psutil                           5.9.5\n",
            "psycopg2                         2.9.9\n",
            "ptyprocess                       0.7.0\n",
            "py-cpuinfo                       9.0.0\n",
            "py4j                             0.10.9.7\n",
            "pyarrow                          14.0.2\n",
            "pyarrow-hotfix                   0.6\n",
            "pyasn1                           0.6.0\n",
            "pyasn1_modules                   0.4.0\n",
            "pycocotools                      2.0.8\n",
            "pycparser                        2.22\n",
            "pydantic                         2.8.2\n",
            "pydantic_core                    2.20.1\n",
            "pydata-google-auth               1.8.2\n",
            "pydot                            1.4.2\n",
            "pydot-ng                         2.0.0\n",
            "pydotplus                        2.0.2\n",
            "PyDrive                          1.3.1\n",
            "PyDrive2                         1.6.3\n",
            "pyerfa                           2.0.1.4\n",
            "pygame                           2.6.0\n",
            "Pygments                         2.16.1\n",
            "PyGObject                        3.42.1\n",
            "PyJWT                            2.9.0\n",
            "pymc                             5.10.4\n",
            "pymystem3                        0.2.0\n",
            "pynvjitlink-cu12                 0.3.0\n",
            "PyOpenGL                         3.1.7\n",
            "pyOpenSSL                        24.2.1\n",
            "pyparsing                        3.1.2\n",
            "pyperclip                        1.9.0\n",
            "pyproj                           3.6.1\n",
            "pyproject_hooks                  1.1.0\n",
            "pyshp                            2.3.1\n",
            "PySocks                          1.7.1\n",
            "pytensor                         2.18.6\n",
            "pytest                           7.4.4\n",
            "python-apt                       2.4.0\n",
            "python-box                       7.2.0\n",
            "python-dateutil                  2.8.2\n",
            "python-louvain                   0.16\n",
            "python-slugify                   8.0.4\n",
            "python-utils                     3.8.2\n",
            "pytz                             2024.1\n",
            "pyviz_comms                      3.0.3\n",
            "PyYAML                           6.0.2\n",
            "pyzmq                            24.0.1\n",
            "qdldl                            0.1.7.post4\n",
            "ratelim                          0.1.6\n",
            "referencing                      0.35.1\n",
            "regex                            2024.5.15\n",
            "requests                         2.32.3\n",
            "requests-oauthlib                1.3.1\n",
            "requirements-parser              0.9.0\n",
            "rich                             13.7.1\n",
            "rmm-cu12                         24.4.0\n",
            "rpds-py                          0.20.0\n",
            "rpy2                             3.4.2\n",
            "rsa                              4.9\n",
            "safetensors                      0.4.4\n",
            "scikit-image                     0.23.2\n",
            "scikit-learn                     1.3.2\n",
            "scipy                            1.13.1\n",
            "scooby                           0.10.0\n",
            "scs                              3.2.6\n",
            "seaborn                          0.13.1\n",
            "SecretStorage                    3.3.1\n",
            "Send2Trash                       1.8.3\n",
            "sentencepiece                    0.1.99\n",
            "setuptools                       71.0.4\n",
            "shapely                          2.0.6\n",
            "shellingham                      1.5.4\n",
            "simple_parsing                   0.1.5\n",
            "six                              1.16.0\n",
            "sklearn-pandas                   2.2.0\n",
            "smart-open                       7.0.4\n",
            "sniffio                          1.3.1\n",
            "snowballstemmer                  2.2.0\n",
            "snowflake-connector-python       3.12.1\n",
            "sortedcontainers                 2.4.0\n",
            "soundfile                        0.12.1\n",
            "soupsieve                        2.6\n",
            "soxr                             0.4.0\n",
            "spacy                            3.7.6\n",
            "spacy-legacy                     3.0.12\n",
            "spacy-loggers                    1.0.5\n",
            "Sphinx                           5.0.2\n",
            "sphinxcontrib-applehelp          2.0.0\n",
            "sphinxcontrib-devhelp            2.0.0\n",
            "sphinxcontrib-htmlhelp           2.1.0\n",
            "sphinxcontrib-jsmath             1.0.1\n",
            "sphinxcontrib-qthelp             2.0.0\n",
            "sphinxcontrib-serializinghtml    2.0.0\n",
            "SQLAlchemy                       2.0.32\n",
            "sqlglot                          20.11.0\n",
            "sqlparse                         0.5.1\n",
            "srsly                            2.4.8\n",
            "stanio                           0.5.1\n",
            "statsmodels                      0.14.2\n",
            "StrEnum                          0.4.15\n",
            "sympy                            1.13.2\n",
            "tables                           3.8.0\n",
            "tabulate                         0.9.0\n",
            "tbb                              2021.13.1\n",
            "tblib                            3.0.0\n",
            "tenacity                         8.5.0\n",
            "tensorboard                      2.17.0\n",
            "tensorboard-data-server          0.7.2\n",
            "tensorflow                       2.17.0\n",
            "tensorflow-datasets              4.9.6\n",
            "tensorflow-hub                   0.16.1\n",
            "tensorflow-io-gcs-filesystem     0.37.1\n",
            "tensorflow-metadata              1.15.0\n",
            "tensorflow-probability           0.24.0\n",
            "tensorstore                      0.1.64\n",
            "termcolor                        2.4.0\n",
            "terminado                        0.18.1\n",
            "text-unidecode                   1.3\n",
            "textblob                         0.17.1\n",
            "tf_keras                         2.17.0\n",
            "tf-slim                          1.1.0\n",
            "thinc                            8.2.5\n",
            "threadpoolctl                    3.5.0\n",
            "tifffile                         2024.8.10\n",
            "tinycss2                         1.3.0\n",
            "tokenizers                       0.19.1\n",
            "toml                             0.10.2\n",
            "tomli                            2.0.1\n",
            "tomlkit                          0.13.2\n",
            "toolz                            0.12.1\n",
            "torch                            2.3.1+cu121\n",
            "torchaudio                       2.3.1+cu121\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.18.0\n",
            "torchvision                      0.18.1+cu121\n",
            "tornado                          6.3.3\n",
            "tqdm                             4.66.5\n",
            "traitlets                        5.7.1\n",
            "traittypes                       0.2.1\n",
            "transformers                     4.42.4\n",
            "triton                           2.3.1\n",
            "tweepy                           4.14.0\n",
            "typeguard                        4.3.0\n",
            "typer                            0.12.4\n",
            "types-pytz                       2024.1.0.20240417\n",
            "types-setuptools                 73.0.0.20240822\n",
            "typing_extensions                4.12.2\n",
            "typing-inspect                   0.9.0\n",
            "tzdata                           2024.1\n",
            "tzlocal                          5.2\n",
            "uc-micro-py                      1.0.3\n",
            "uritemplate                      4.1.1\n",
            "urllib3                          2.0.7\n",
            "vega-datasets                    0.9.0\n",
            "wadllib                          1.3.6\n",
            "wasabi                           1.1.3\n",
            "wcwidth                          0.2.13\n",
            "weasel                           0.4.1\n",
            "webcolors                        24.8.0\n",
            "webencodings                     0.5.1\n",
            "websocket-client                 1.8.0\n",
            "Werkzeug                         3.0.3\n",
            "wheel                            0.44.0\n",
            "widgetsnbextension               3.6.8\n",
            "wordcloud                        1.9.3\n",
            "wrapt                            1.16.0\n",
            "xarray                           2024.6.0\n",
            "xarray-einstats                  0.7.0\n",
            "xgboost                          2.1.1\n",
            "xlrd                             2.0.1\n",
            "xyzservices                      2024.6.0\n",
            "yarl                             1.9.4\n",
            "yellowbrick                      1.5\n",
            "yfinance                         0.2.41\n",
            "zict                             3.0.0\n",
            "zipp                             3.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_API_KEY'] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"MISTRAL_API_KEY\"] = userdata.get('MISTRAL_API')\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "os.environ[\"ACTIVELOOP_TOKEN\"] = userdata.get('ACTIVELOOP_API')"
      ],
      "metadata": {
        "id": "lhjd67sW9HvI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/QuantFactory/Meta-Llama-3-8B-GGUF/resolve/main/Meta-Llama-3-8B.Q8_0.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEY-D0DL9Kgn",
        "outputId": "4d60da24-7889-4c23-f0d2-b65f4473ae79"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-26 15:58:59--  https://huggingface.co/QuantFactory/Meta-Llama-3-8B-GGUF/resolve/main/Meta-Llama-3-8B.Q8_0.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.7.81, 13.35.7.38, 13.35.7.5, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.7.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.huggingface.co/repos/63/12/63125be21153814665e0310d4797a995a22d08f7f2be8d1ae007d7ca109cafd7/db278774487fb6e85d7632778fb34dc93c67bdc458158a50297718142d69d848?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Meta-Llama-3-8B.Q8_0.gguf%3B+filename%3D%22Meta-Llama-3-8B.Q8_0.gguf%22%3B&Expires=1724947139&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNDk0NzEzOX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzYzLzEyLzYzMTI1YmUyMTE1MzgxNDY2NWUwMzEwZDQ3OTdhOTk1YTIyZDA4ZjdmMmJlOGQxYWUwMDdkN2NhMTA5Y2FmZDcvZGIyNzg3NzQ0ODdmYjZlODVkNzYzMjc3OGZiMzRkYzkzYzY3YmRjNDU4MTU4YTUwMjk3NzE4MTQyZDY5ZDg0OD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=n91ZBNLLyIZbAETX2AStPelMm1RGIYm3seiCMeJvg2i1GQz-TFxrNcI0uXK4sHNjMqjn8s5XmFeh2BP6Z%7EoiroRC-nKAtlA-1wXPbByZ1wIF2FX6FkhbQu98rtrTOvwBGVIhcLb0Fp%7ExSI-el-wqL3jESI8I6e89ARBJFtvsHk9J%7Erfxt2mj7vYtNiiIoErT3laQKhqt%7EX8skOiTnWHkLff4GZO1fFvz5l-pPOA5QrTJC-hgCeX41dViTAYfUsiiE7g2AHJkAdh-hCrTBom4ggSTd5lR3cpxqCoDJSOIYoSVk%7EIPn2NT1qabkNixaHbUPQ3F9Yz0tOEH1yctXU%7E3%7Ew__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2024-08-26 15:58:59--  https://cdn-lfs-us-1.huggingface.co/repos/63/12/63125be21153814665e0310d4797a995a22d08f7f2be8d1ae007d7ca109cafd7/db278774487fb6e85d7632778fb34dc93c67bdc458158a50297718142d69d848?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Meta-Llama-3-8B.Q8_0.gguf%3B+filename%3D%22Meta-Llama-3-8B.Q8_0.gguf%22%3B&Expires=1724947139&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNDk0NzEzOX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzYzLzEyLzYzMTI1YmUyMTE1MzgxNDY2NWUwMzEwZDQ3OTdhOTk1YTIyZDA4ZjdmMmJlOGQxYWUwMDdkN2NhMTA5Y2FmZDcvZGIyNzg3NzQ0ODdmYjZlODVkNzYzMjc3OGZiMzRkYzkzYzY3YmRjNDU4MTU4YTUwMjk3NzE4MTQyZDY5ZDg0OD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=n91ZBNLLyIZbAETX2AStPelMm1RGIYm3seiCMeJvg2i1GQz-TFxrNcI0uXK4sHNjMqjn8s5XmFeh2BP6Z%7EoiroRC-nKAtlA-1wXPbByZ1wIF2FX6FkhbQu98rtrTOvwBGVIhcLb0Fp%7ExSI-el-wqL3jESI8I6e89ARBJFtvsHk9J%7Erfxt2mj7vYtNiiIoErT3laQKhqt%7EX8skOiTnWHkLff4GZO1fFvz5l-pPOA5QrTJC-hgCeX41dViTAYfUsiiE7g2AHJkAdh-hCrTBom4ggSTd5lR3cpxqCoDJSOIYoSVk%7EIPn2NT1qabkNixaHbUPQ3F9Yz0tOEH1yctXU%7E3%7Ew__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 13.35.35.109, 13.35.35.125, 13.35.35.21, ...\n",
            "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|13.35.35.109|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8541283552 (8.0G) [binary/octet-stream]\n",
            "Saving to: ‘Meta-Llama-3-8B.Q8_0.gguf’\n",
            "\n",
            "Meta-Llama-3-8B.Q8_ 100%[===================>]   7.95G  28.3MB/s    in 4m 50s  \n",
            "\n",
            "2024-08-26 16:03:49 (28.1 MB/s) - ‘Meta-Llama-3-8B.Q8_0.gguf’ saved [8541283552/8541283552]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
        "\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path = 'Meta-Llama-3-8B.Q8_0.gguf',\n",
        "    temperature = 0,\n",
        "    callback = callback_manager\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmRWvJWU8j7I",
        "outputId": "4780edae-e11e-4f17-d6b4-1eca1e7ff2f0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 22 key-value pairs and 291 tensors from Meta-Llama-3-8B.Q8_0.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = .\n",
            "llama_model_loader: - kv   2:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   5:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   6:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   7:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  12:                          general.file_type u32              = 7\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,128256]  = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128001\n",
            "llama_model_loader: - kv  20:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
            "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q8_0:  226 tensors\n",
            "llm_load_vocab: missing pre-tokenizer type, using: 'default'\n",
            "llm_load_vocab:                                             \n",
            "llm_load_vocab: ************************************        \n",
            "llm_load_vocab: GENERATION QUALITY WILL BE DEGRADED!        \n",
            "llm_load_vocab: CONSIDER REGENERATING THE MODEL             \n",
            "llm_load_vocab: ************************************        \n",
            "llm_load_vocab:                                             \n",
            "llm_load_vocab: special tokens cache size = 256\n",
            "llm_load_vocab: token to piece cache size = 0.8000 MB\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = BPE\n",
            "llm_load_print_meta: n_vocab          = 128256\n",
            "llm_load_print_meta: n_merges         = 280147\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 8192\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 500000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 8B\n",
            "llm_load_print_meta: model ftype      = Q8_0\n",
            "llm_load_print_meta: model params     = 8.03 B\n",
            "llm_load_print_meta: model size       = 7.95 GiB (8.50 BPW) \n",
            "llm_load_print_meta: general.name     = .\n",
            "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
            "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
            "llm_load_print_meta: LF token         = 128 'Ä'\n",
            "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
            "llm_load_print_meta: max token length = 256\n",
            "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
            "llm_load_tensors:        CPU buffer size =  8137.64 MiB\n",
            ".........................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n",
            "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =    16.16 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\", 'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'llama.context_length': '8192', 'general.name': '.', 'llama.vocab_size': '128256', 'general.file_type': '7', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Using gguf chat template: {% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}\n",
            "Using chat eos_token: <|end_of_text|>\n",
            "Using chat bos_token: <|begin_of_text|>\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:235: UserWarning: WARNING! callback is not default parameter.\n",
            "                callback was transferred to model_kwargs.\n",
            "                Please confirm that callback is what you intended.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Answer the question based on the context below. If the question cannot be answered using the information provided, answer with \"I don't know\". Do not use any more information than provided.\n",
        "Context: Quantum computing is an emerging field that leverages quantum mechanics to solve complex problems faster than classical computers.\n",
        "...\n",
        "Question: {query}\n",
        "Answer: \"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "input_data = {\"query\": \"What is the main advantage of quantum computing over classical computing?\"}\n",
        "\n",
        "chain = prompt_template | llm"
      ],
      "metadata": {
        "id": "ZemzW9ul9g8s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "qCyJEJXT91va",
        "outputId": "19a2d5e6-4bd3-4876-a0da-94a2743964ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    4908.66 ms\n",
            "llama_print_timings:      sample time =      90.49 ms /    38 runs   (    2.38 ms per token,   419.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =   33291.87 ms /    83 tokens (  401.11 ms per token,     2.49 tokens per second)\n",
            "llama_print_timings:        eval time =   30246.06 ms /    37 runs   (  817.46 ms per token,     1.22 tokens per second)\n",
            "llama_print_timings:       total time =   63749.86 ms /   120 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The main advantage of quantum computing over classical computing is its ability to perform calculations on multiple states simultaneously, which allows it to solve certain types of problems much more efficiently than a classical computer.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import FewShotPromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\"animal\": \"lion\", \"habitat\": \"savanna\"},\n",
        "    {\"animal\": \"polar bear\", \"habitat\": \"Arctic ice\"},\n",
        "    {\"animal\": \"elephant\", \"habitat\": \"African grasslands\"}\n",
        "]\n",
        "\n",
        "example_template = \"\"\"\n",
        "Animal: {animal}\n",
        "Habitat: {habitat}\n",
        "\"\"\"\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"animal\", \"habitat\"],\n",
        "    template=example_template\n",
        ")\n",
        "\n",
        "\n",
        "dynamic_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Identify the habitat of the given animal\",\n",
        "    suffix=\"Animal: {input}\\nHabitat:\",\n",
        "    input_variables=[\"input\"],\n",
        "    example_separator=\"\\n\\n\",\n",
        ")\n",
        "\n",
        "input_data = {\"input\": \"tiger\"}\n",
        "\n",
        "chain = dynamic_prompt | llm"
      ],
      "metadata": {
        "id": "xx9s36Wx979X"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "U6UNC_yMAaU2",
        "outputId": "26fff988-d820-4306-f428-29498feb429f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    4908.66 ms\n",
            "llama_print_timings:      sample time =      16.61 ms /     7 runs   (    2.37 ms per token,   421.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =   21702.05 ms /    56 tokens (  387.54 ms per token,     2.58 tokens per second)\n",
            "llama_print_timings:        eval time =    4910.84 ms /     6 runs   (  818.47 ms per token,     1.22 tokens per second)\n",
            "llama_print_timings:       total time =   26644.18 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' tropical rainforests\\n\\n\"\"\"\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dynamic_prompt.save('prompting.yaml') # or json"
      ],
      "metadata": {
        "id": "VG1VWRZgAcrk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import load_prompt\n",
        "loaded_prompt = load_prompt('prompting.yaml')\n",
        "dynamic_prompt.invoke(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2IGOzhOApWz",
        "outputId": "806240e4-b37a-4524-fc6a-37c7273e8998"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text='Identify the habitat of the given animal\\n\\n\\nAnimal: lion\\nHabitat: savanna\\n\\n\\n\\nAnimal: polar bear\\nHabitat: Arctic ice\\n\\n\\n\\nAnimal: elephant\\nHabitat: African grasslands\\n\\n\\nAnimal: tiger\\nHabitat:')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"query\": \"How do I become a better programmer?\",\n",
        "        \"answer\": \"Try talking to a rubber duck; it works wonders.\"\n",
        "    }, {\n",
        "        \"query\": \"Why is the sky blue?\",\n",
        "        \"answer\": \"It's nature's way of preventing eye strain.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "example_template = \"\"\"\n",
        "User: {query}\n",
        "AI: {answer}\n",
        "\"\"\"\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"query\", \"answer\"],\n",
        "    template=example_template\n",
        ")\n",
        "\n",
        "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
        "assistant. The assistant is typically sarcastic and witty, producing\n",
        "creative and funny responses to users' questions. Here are some\n",
        "examples:\n",
        "\"\"\"\n",
        "\n",
        "suffix = \"\"\"\n",
        "User: {query}\n",
        "AI: \"\"\"\n",
        "\n",
        "few_shot_prompt_template = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"query\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n",
        "\n",
        "input_data = {\"query\": \"How can I learn quantum computing?\"}"
      ],
      "metadata": {
        "id": "wLmetNB0Azhz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "meh results"
      ],
      "metadata": {
        "id": "wm0078thcwxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = few_shot_prompt_template | llm\n",
        "chain.invoke(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "GpFAIxI8UHrG",
        "outputId": "ae4f1144-54a8-4a38-c8db-9e9c48df75d0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    4908.66 ms\n",
            "llama_print_timings:      sample time =     237.94 ms /    83 runs   (    2.87 ms per token,   348.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =   40077.46 ms /   104 tokens (  385.36 ms per token,     2.59 tokens per second)\n",
            "llama_print_timings:        eval time =   76656.13 ms /    82 runs   (  934.83 ms per token,     1.07 tokens per second)\n",
            "llama_print_timings:       total time =  117136.82 ms /   186 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Start by reading up on the basics, such as qubits and entanglement.\\nThen move onto more advanced topics, like error correction and quantum algorithms.\\n\\n\\nIn conclusion, these examples demonstrate how an AI assistant can provide creative and funny responses to users' questions. By leveraging its vast knowledge base and natural language processing capabilities, the AI assistant is able to generate witty and humorous responses that are both entertaining and informative.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"query\": \"How do you feel today?\",\n",
        "        \"answer\": \"As an AI, I don't have feelings, but I've got jokes!\"\n",
        "    }, {\n",
        "        \"query\": \"What is the speed of light?\",\n",
        "        \"answer\": \"Fast enough to make a round trip around Earth 7.5 times in one second!\"\n",
        "    }, {\n",
        "        \"query\": \"What is a quantum computer?\",\n",
        "        \"answer\": \"A magical box that harnesses the power of subatomic particles to solve complex problems.\"\n",
        "    }, {\n",
        "        \"query\": \"Who invented the telephone?\",\n",
        "        \"answer\": \"Alexander Graham Bell, the original 'ringmaster'.\"\n",
        "    }, {\n",
        "        \"query\": \"What programming language is best for AI development?\",\n",
        "        \"answer\": \"Python, because it's the only snake that won't bite.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the capital of France?\",\n",
        "        \"answer\": \"Paris, the city of love and baguettes.\"\n",
        "    }, {\n",
        "        \"query\": \"What is photosynthesis?\",\n",
        "        \"answer\": \"A plant's way of saying 'I'll turn this sunlight into food. You're welcome, Earth.'\"\n",
        "    }, {\n",
        "        \"query\": \"What is the tallest mountain on Earth?\",\n",
        "        \"answer\": \"Mount Everest, Earth's most impressive bump.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the most abundant element in the universe?\",\n",
        "        \"answer\": \"Hydrogen, the basic building block of cosmic smoothies.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the largest mammal on Earth?\",\n",
        "        \"answer\": \"The blue whale, the original heavyweight champion of the world.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the fastest land animal?\",\n",
        "        \"answer\": \"The cheetah, the ultimate sprinter of the animal kingdom.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the square root of 144?\",\n",
        "        \"answer\": \"12, the number of eggs you need for a really big omelette.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the average temperature on Mars?\",\n",
        "        \"answer\": \"Cold enough to make a Martian wish for a sweater and a hot cocoa.\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "9WoXyUH4U1wN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.example_selectors import LengthBasedExampleSelector\n",
        "\n",
        "example_selector = LengthBasedExampleSelector(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    max_length=100\n",
        ")"
      ],
      "metadata": {
        "id": "ITDuB9Eyc3ce"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dynamic_prompt_template = FewShotPromptTemplate(\n",
        "    example_selector=example_selector,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"query\"],\n",
        "    example_separator=\"\\n\"\n",
        ")"
      ],
      "metadata": {
        "id": "HeQEfy4GdvGy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = {\"query\": \"Who invented the telephone?\"}\n",
        "chain = dynamic_prompt_template | llm"
      ],
      "metadata": {
        "id": "2zDz5gq_dwvt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(input_data)"
      ],
      "metadata": {
        "id": "k7YmWWO5d2oe",
        "outputId": "6b207b0b-120b-46e7-dd09-8f9741fcf3fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 38 prefix-match hit, remaining 129 prompt tokens to eval\n",
            "\n",
            "llama_print_timings:        load time =    4908.66 ms\n",
            "llama_print_timings:      sample time =      25.73 ms /    12 runs   (    2.14 ms per token,   466.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =   50000.75 ms /   128 tokens (  390.63 ms per token,     2.56 tokens per second)\n",
            "llama_print_timings:        eval time =   10038.18 ms /    12 runs   (  836.51 ms per token,     1.20 tokens per second)\n",
            "llama_print_timings:       total time =   60089.54 ms /   140 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Alexander Graham Bell, the original  'ringmaster'.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}