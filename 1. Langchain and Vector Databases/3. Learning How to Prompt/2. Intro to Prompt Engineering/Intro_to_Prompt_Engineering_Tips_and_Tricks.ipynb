{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MWR1jRM_jFOf"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_community llama-cpp-python -q\n",
        "clear_output()\n",
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq_0fWWijJeR",
        "outputId": "64489ea7-a041-4b15-cf69-2d24cc054bb2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                          Version\n",
            "-------------------------------- ---------------------\n",
            "absl-py                          1.4.0\n",
            "accelerate                       0.32.1\n",
            "aiohappyeyeballs                 2.4.0\n",
            "aiohttp                          3.10.5\n",
            "aiosignal                        1.3.1\n",
            "alabaster                        0.7.16\n",
            "albucore                         0.0.13\n",
            "albumentations                   1.4.14\n",
            "altair                           4.2.2\n",
            "annotated-types                  0.7.0\n",
            "anyio                            3.7.1\n",
            "argon2-cffi                      23.1.0\n",
            "argon2-cffi-bindings             21.2.0\n",
            "array_record                     0.5.1\n",
            "arviz                            0.18.0\n",
            "asn1crypto                       1.5.1\n",
            "astropy                          6.1.2\n",
            "astropy-iers-data                0.2024.8.19.0.32.16\n",
            "astunparse                       1.6.3\n",
            "async-timeout                    4.0.3\n",
            "atpublic                         4.1.0\n",
            "attrs                            24.2.0\n",
            "audioread                        3.0.1\n",
            "autograd                         1.6.2\n",
            "babel                            2.16.0\n",
            "backcall                         0.2.0\n",
            "beautifulsoup4                   4.12.3\n",
            "bidict                           0.23.1\n",
            "bigframes                        1.15.0\n",
            "bleach                           6.1.0\n",
            "blinker                          1.4\n",
            "blis                             0.7.11\n",
            "blosc2                           2.0.0\n",
            "bokeh                            3.4.3\n",
            "bqplot                           0.12.43\n",
            "branca                           0.7.2\n",
            "build                            1.2.1\n",
            "CacheControl                     0.14.0\n",
            "cachetools                       5.5.0\n",
            "catalogue                        2.0.10\n",
            "certifi                          2024.7.4\n",
            "cffi                             1.17.0\n",
            "chardet                          5.2.0\n",
            "charset-normalizer               3.3.2\n",
            "chex                             0.1.86\n",
            "clarabel                         0.9.0\n",
            "click                            8.1.7\n",
            "click-plugins                    1.1.1\n",
            "cligj                            0.7.2\n",
            "cloudpathlib                     0.18.1\n",
            "cloudpickle                      2.2.1\n",
            "cmake                            3.30.2\n",
            "cmdstanpy                        1.2.4\n",
            "colorcet                         3.1.0\n",
            "colorlover                       0.3.0\n",
            "colour                           0.1.5\n",
            "community                        1.0.0b1\n",
            "confection                       0.1.5\n",
            "cons                             0.4.6\n",
            "contextlib2                      21.6.0\n",
            "contourpy                        1.2.1\n",
            "cryptography                     43.0.0\n",
            "cuda-python                      12.2.1\n",
            "cudf-cu12                        24.4.1\n",
            "cufflinks                        0.17.3\n",
            "cupy-cuda12x                     12.2.0\n",
            "cvxopt                           1.3.2\n",
            "cvxpy                            1.5.3\n",
            "cycler                           0.12.1\n",
            "cymem                            2.0.8\n",
            "Cython                           3.0.11\n",
            "dask                             2024.7.1\n",
            "dataclasses-json                 0.6.7\n",
            "datascience                      0.17.6\n",
            "db-dtypes                        1.3.0\n",
            "dbus-python                      1.2.18\n",
            "debugpy                          1.6.6\n",
            "decorator                        4.4.2\n",
            "defusedxml                       0.7.1\n",
            "diskcache                        5.6.3\n",
            "distributed                      2024.7.1\n",
            "distro                           1.7.0\n",
            "dlib                             19.24.2\n",
            "dm-tree                          0.1.8\n",
            "docstring_parser                 0.16\n",
            "docutils                         0.18.1\n",
            "dopamine_rl                      4.0.9\n",
            "duckdb                           0.10.3\n",
            "earthengine-api                  0.1.417\n",
            "easydict                         1.13\n",
            "ecos                             2.0.14\n",
            "editdistance                     0.8.1\n",
            "eerepr                           0.0.4\n",
            "einops                           0.8.0\n",
            "en-core-web-sm                   3.7.1\n",
            "entrypoints                      0.4\n",
            "et-xmlfile                       1.1.0\n",
            "etils                            1.7.0\n",
            "etuples                          0.3.9\n",
            "eval_type_backport               0.2.0\n",
            "exceptiongroup                   1.2.2\n",
            "fastai                           2.7.16\n",
            "fastcore                         1.5.55\n",
            "fastdownload                     0.0.7\n",
            "fastjsonschema                   2.20.0\n",
            "fastprogress                     1.0.3\n",
            "fastrlock                        0.8.2\n",
            "filelock                         3.15.4\n",
            "fiona                            1.9.6\n",
            "firebase-admin                   6.5.0\n",
            "Flask                            2.2.5\n",
            "flatbuffers                      24.3.25\n",
            "flax                             0.8.4\n",
            "folium                           0.17.0\n",
            "fonttools                        4.53.1\n",
            "frozendict                       2.4.4\n",
            "frozenlist                       1.4.1\n",
            "fsspec                           2024.6.1\n",
            "future                           1.0.0\n",
            "gast                             0.6.0\n",
            "gcsfs                            2024.6.1\n",
            "GDAL                             3.6.4\n",
            "gdown                            5.1.0\n",
            "geemap                           0.34.0\n",
            "gensim                           4.3.3\n",
            "geocoder                         1.38.1\n",
            "geographiclib                    2.0\n",
            "geopandas                        0.14.4\n",
            "geopy                            2.4.1\n",
            "gin-config                       0.5.0\n",
            "glob2                            0.7\n",
            "google                           2.0.3\n",
            "google-ai-generativelanguage     0.6.6\n",
            "google-api-core                  2.19.1\n",
            "google-api-python-client         2.137.0\n",
            "google-auth                      2.27.0\n",
            "google-auth-httplib2             0.2.0\n",
            "google-auth-oauthlib             1.2.1\n",
            "google-cloud-aiplatform          1.63.0\n",
            "google-cloud-bigquery            3.25.0\n",
            "google-cloud-bigquery-connection 1.15.5\n",
            "google-cloud-bigquery-storage    2.25.0\n",
            "google-cloud-bigtable            2.26.0\n",
            "google-cloud-core                2.4.1\n",
            "google-cloud-datastore           2.19.0\n",
            "google-cloud-firestore           2.16.1\n",
            "google-cloud-functions           1.16.5\n",
            "google-cloud-iam                 2.15.2\n",
            "google-cloud-language            2.13.4\n",
            "google-cloud-pubsub              2.23.0\n",
            "google-cloud-resource-manager    1.12.5\n",
            "google-cloud-storage             2.8.0\n",
            "google-cloud-translate           3.15.5\n",
            "google-colab                     1.0.0\n",
            "google-crc32c                    1.5.0\n",
            "google-generativeai              0.7.2\n",
            "google-pasta                     0.2.0\n",
            "google-resumable-media           2.7.2\n",
            "googleapis-common-protos         1.63.2\n",
            "googledrivedownloader            0.4\n",
            "graphviz                         0.20.3\n",
            "greenlet                         3.0.3\n",
            "grpc-google-iam-v1               0.13.1\n",
            "grpcio                           1.64.1\n",
            "grpcio-status                    1.48.2\n",
            "gspread                          6.0.2\n",
            "gspread-dataframe                3.3.1\n",
            "gym                              0.25.2\n",
            "gym-notices                      0.0.8\n",
            "h11                              0.14.0\n",
            "h5netcdf                         1.3.0\n",
            "h5py                             3.11.0\n",
            "holidays                         0.55\n",
            "holoviews                        1.18.3\n",
            "html5lib                         1.1\n",
            "httpcore                         1.0.5\n",
            "httpimport                       1.3.1\n",
            "httplib2                         0.22.0\n",
            "httpx                            0.27.0\n",
            "huggingface-hub                  0.23.5\n",
            "humanize                         4.10.0\n",
            "hyperopt                         0.2.7\n",
            "ibis-framework                   8.0.0\n",
            "idna                             3.7\n",
            "imageio                          2.34.2\n",
            "imageio-ffmpeg                   0.5.1\n",
            "imagesize                        1.4.1\n",
            "imbalanced-learn                 0.12.3\n",
            "imgaug                           0.4.0\n",
            "immutabledict                    4.2.0\n",
            "importlib_metadata               8.4.0\n",
            "importlib_resources              6.4.3\n",
            "imutils                          0.5.4\n",
            "inflect                          7.3.1\n",
            "iniconfig                        2.0.0\n",
            "intel-cmplr-lib-ur               2024.2.1\n",
            "intel-openmp                     2024.2.1\n",
            "ipyevents                        2.0.2\n",
            "ipyfilechooser                   0.6.0\n",
            "ipykernel                        5.5.6\n",
            "ipyleaflet                       0.18.2\n",
            "ipyparallel                      8.8.0\n",
            "ipython                          7.34.0\n",
            "ipython-genutils                 0.2.0\n",
            "ipython-sql                      0.5.0\n",
            "ipytree                          0.2.2\n",
            "ipywidgets                       7.7.1\n",
            "itsdangerous                     2.2.0\n",
            "jax                              0.4.26\n",
            "jaxlib                           0.4.26+cuda12.cudnn89\n",
            "jeepney                          0.7.1\n",
            "jellyfish                        1.1.0\n",
            "jieba                            0.42.1\n",
            "Jinja2                           3.1.4\n",
            "joblib                           1.4.2\n",
            "jsonpatch                        1.33\n",
            "jsonpickle                       3.2.2\n",
            "jsonpointer                      3.0.0\n",
            "jsonschema                       4.23.0\n",
            "jsonschema-specifications        2023.12.1\n",
            "jupyter-client                   6.1.12\n",
            "jupyter-console                  6.1.0\n",
            "jupyter_core                     5.7.2\n",
            "jupyter-server                   1.24.0\n",
            "jupyterlab_pygments              0.3.0\n",
            "jupyterlab_widgets               3.0.11\n",
            "kaggle                           1.6.17\n",
            "kagglehub                        0.2.9\n",
            "keras                            3.4.1\n",
            "keyring                          23.5.0\n",
            "kiwisolver                       1.4.5\n",
            "langchain                        0.2.14\n",
            "langchain-community              0.2.12\n",
            "langchain-core                   0.2.35\n",
            "langchain-text-splitters         0.2.2\n",
            "langcodes                        3.4.0\n",
            "langsmith                        0.1.104\n",
            "language_data                    1.2.0\n",
            "launchpadlib                     1.10.16\n",
            "lazr.restfulclient               0.14.4\n",
            "lazr.uri                         1.0.6\n",
            "lazy_loader                      0.4\n",
            "libclang                         18.1.1\n",
            "librosa                          0.10.2.post1\n",
            "lightgbm                         4.4.0\n",
            "linkify-it-py                    2.0.3\n",
            "llama_cpp_python                 0.2.89\n",
            "llvmlite                         0.43.0\n",
            "locket                           1.0.0\n",
            "logical-unification              0.4.6\n",
            "lxml                             4.9.4\n",
            "malloy                           2024.1089\n",
            "marisa-trie                      1.2.0\n",
            "Markdown                         3.7\n",
            "markdown-it-py                   3.0.0\n",
            "MarkupSafe                       2.1.5\n",
            "marshmallow                      3.22.0\n",
            "matplotlib                       3.7.1\n",
            "matplotlib-inline                0.1.7\n",
            "matplotlib-venn                  0.11.10\n",
            "mdit-py-plugins                  0.4.1\n",
            "mdurl                            0.1.2\n",
            "miniKanren                       1.0.3\n",
            "missingno                        0.5.2\n",
            "mistune                          0.8.4\n",
            "mizani                           0.9.3\n",
            "mkl                              2024.2.1\n",
            "ml-dtypes                        0.4.0\n",
            "mlxtend                          0.23.1\n",
            "more-itertools                   10.3.0\n",
            "moviepy                          1.0.3\n",
            "mpmath                           1.3.0\n",
            "msgpack                          1.0.8\n",
            "multidict                        6.0.5\n",
            "multipledispatch                 1.0.0\n",
            "multitasking                     0.0.11\n",
            "murmurhash                       1.0.10\n",
            "music21                          9.1.0\n",
            "mypy-extensions                  1.0.0\n",
            "namex                            0.0.8\n",
            "natsort                          8.4.0\n",
            "nbclassic                        1.1.0\n",
            "nbclient                         0.10.0\n",
            "nbconvert                        6.5.4\n",
            "nbformat                         5.10.4\n",
            "nest-asyncio                     1.6.0\n",
            "networkx                         3.3\n",
            "nibabel                          5.0.1\n",
            "nltk                             3.8.1\n",
            "notebook                         6.5.5\n",
            "notebook_shim                    0.2.4\n",
            "numba                            0.60.0\n",
            "numexpr                          2.10.1\n",
            "numpy                            1.26.4\n",
            "nvtx                             0.2.10\n",
            "oauth2client                     4.1.3\n",
            "oauthlib                         3.2.2\n",
            "opencv-contrib-python            4.10.0.84\n",
            "opencv-python                    4.10.0.84\n",
            "opencv-python-headless           4.10.0.84\n",
            "openpyxl                         3.1.5\n",
            "opt-einsum                       3.3.0\n",
            "optax                            0.2.2\n",
            "optree                           0.12.1\n",
            "orbax-checkpoint                 0.6.0\n",
            "orjson                           3.10.7\n",
            "osqp                             0.6.7.post0\n",
            "packaging                        24.1\n",
            "pandas                           2.1.4\n",
            "pandas-datareader                0.10.0\n",
            "pandas-gbq                       0.23.1\n",
            "pandas-stubs                     2.1.4.231227\n",
            "pandocfilters                    1.5.1\n",
            "panel                            1.4.5\n",
            "param                            2.1.1\n",
            "parso                            0.8.4\n",
            "parsy                            2.1\n",
            "partd                            1.4.2\n",
            "pathlib                          1.0.1\n",
            "patsy                            0.5.6\n",
            "peewee                           3.17.6\n",
            "pexpect                          4.9.0\n",
            "pickleshare                      0.7.5\n",
            "Pillow                           9.4.0\n",
            "pip                              24.1.2\n",
            "pip-tools                        7.4.1\n",
            "platformdirs                     4.2.2\n",
            "plotly                           5.15.0\n",
            "plotnine                         0.12.4\n",
            "pluggy                           1.5.0\n",
            "polars                           0.20.2\n",
            "pooch                            1.8.2\n",
            "portpicker                       1.5.2\n",
            "prefetch_generator               1.0.3\n",
            "preshed                          3.0.9\n",
            "prettytable                      3.11.0\n",
            "proglog                          0.1.10\n",
            "progressbar2                     4.2.0\n",
            "prometheus_client                0.20.0\n",
            "promise                          2.3\n",
            "prompt_toolkit                   3.0.47\n",
            "prophet                          1.1.5\n",
            "proto-plus                       1.24.0\n",
            "protobuf                         3.20.3\n",
            "psutil                           5.9.5\n",
            "psycopg2                         2.9.9\n",
            "ptyprocess                       0.7.0\n",
            "py-cpuinfo                       9.0.0\n",
            "py4j                             0.10.9.7\n",
            "pyarrow                          14.0.2\n",
            "pyarrow-hotfix                   0.6\n",
            "pyasn1                           0.6.0\n",
            "pyasn1_modules                   0.4.0\n",
            "pycocotools                      2.0.8\n",
            "pycparser                        2.22\n",
            "pydantic                         2.8.2\n",
            "pydantic_core                    2.20.1\n",
            "pydata-google-auth               1.8.2\n",
            "pydot                            1.4.2\n",
            "pydot-ng                         2.0.0\n",
            "pydotplus                        2.0.2\n",
            "PyDrive                          1.3.1\n",
            "PyDrive2                         1.6.3\n",
            "pyerfa                           2.0.1.4\n",
            "pygame                           2.6.0\n",
            "Pygments                         2.16.1\n",
            "PyGObject                        3.42.1\n",
            "PyJWT                            2.9.0\n",
            "pymc                             5.10.4\n",
            "pymystem3                        0.2.0\n",
            "pynvjitlink-cu12                 0.3.0\n",
            "PyOpenGL                         3.1.7\n",
            "pyOpenSSL                        24.2.1\n",
            "pyparsing                        3.1.2\n",
            "pyperclip                        1.9.0\n",
            "pyproj                           3.6.1\n",
            "pyproject_hooks                  1.1.0\n",
            "pyshp                            2.3.1\n",
            "PySocks                          1.7.1\n",
            "pytensor                         2.18.6\n",
            "pytest                           7.4.4\n",
            "python-apt                       2.4.0\n",
            "python-box                       7.2.0\n",
            "python-dateutil                  2.8.2\n",
            "python-louvain                   0.16\n",
            "python-slugify                   8.0.4\n",
            "python-utils                     3.8.2\n",
            "pytz                             2024.1\n",
            "pyviz_comms                      3.0.3\n",
            "PyYAML                           6.0.2\n",
            "pyzmq                            24.0.1\n",
            "qdldl                            0.1.7.post4\n",
            "ratelim                          0.1.6\n",
            "referencing                      0.35.1\n",
            "regex                            2024.5.15\n",
            "requests                         2.32.3\n",
            "requests-oauthlib                1.3.1\n",
            "requirements-parser              0.9.0\n",
            "rich                             13.7.1\n",
            "rmm-cu12                         24.4.0\n",
            "rpds-py                          0.20.0\n",
            "rpy2                             3.4.2\n",
            "rsa                              4.9\n",
            "safetensors                      0.4.4\n",
            "scikit-image                     0.23.2\n",
            "scikit-learn                     1.3.2\n",
            "scipy                            1.13.1\n",
            "scooby                           0.10.0\n",
            "scs                              3.2.6\n",
            "seaborn                          0.13.1\n",
            "SecretStorage                    3.3.1\n",
            "Send2Trash                       1.8.3\n",
            "sentencepiece                    0.1.99\n",
            "setuptools                       71.0.4\n",
            "shapely                          2.0.6\n",
            "shellingham                      1.5.4\n",
            "simple_parsing                   0.1.5\n",
            "six                              1.16.0\n",
            "sklearn-pandas                   2.2.0\n",
            "smart-open                       7.0.4\n",
            "sniffio                          1.3.1\n",
            "snowballstemmer                  2.2.0\n",
            "snowflake-connector-python       3.12.1\n",
            "sortedcontainers                 2.4.0\n",
            "soundfile                        0.12.1\n",
            "soupsieve                        2.6\n",
            "soxr                             0.4.0\n",
            "spacy                            3.7.6\n",
            "spacy-legacy                     3.0.12\n",
            "spacy-loggers                    1.0.5\n",
            "Sphinx                           5.0.2\n",
            "sphinxcontrib-applehelp          2.0.0\n",
            "sphinxcontrib-devhelp            2.0.0\n",
            "sphinxcontrib-htmlhelp           2.1.0\n",
            "sphinxcontrib-jsmath             1.0.1\n",
            "sphinxcontrib-qthelp             2.0.0\n",
            "sphinxcontrib-serializinghtml    2.0.0\n",
            "SQLAlchemy                       2.0.32\n",
            "sqlglot                          20.11.0\n",
            "sqlparse                         0.5.1\n",
            "srsly                            2.4.8\n",
            "stanio                           0.5.1\n",
            "statsmodels                      0.14.2\n",
            "StrEnum                          0.4.15\n",
            "sympy                            1.13.2\n",
            "tables                           3.8.0\n",
            "tabulate                         0.9.0\n",
            "tbb                              2021.13.1\n",
            "tblib                            3.0.0\n",
            "tenacity                         8.5.0\n",
            "tensorboard                      2.17.0\n",
            "tensorboard-data-server          0.7.2\n",
            "tensorflow                       2.17.0\n",
            "tensorflow-datasets              4.9.6\n",
            "tensorflow-hub                   0.16.1\n",
            "tensorflow-io-gcs-filesystem     0.37.1\n",
            "tensorflow-metadata              1.15.0\n",
            "tensorflow-probability           0.24.0\n",
            "tensorstore                      0.1.64\n",
            "termcolor                        2.4.0\n",
            "terminado                        0.18.1\n",
            "text-unidecode                   1.3\n",
            "textblob                         0.17.1\n",
            "tf_keras                         2.17.0\n",
            "tf-slim                          1.1.0\n",
            "thinc                            8.2.5\n",
            "threadpoolctl                    3.5.0\n",
            "tifffile                         2024.8.10\n",
            "tinycss2                         1.3.0\n",
            "tokenizers                       0.19.1\n",
            "toml                             0.10.2\n",
            "tomli                            2.0.1\n",
            "tomlkit                          0.13.2\n",
            "toolz                            0.12.1\n",
            "torch                            2.3.1+cu121\n",
            "torchaudio                       2.3.1+cu121\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.18.0\n",
            "torchvision                      0.18.1+cu121\n",
            "tornado                          6.3.3\n",
            "tqdm                             4.66.5\n",
            "traitlets                        5.7.1\n",
            "traittypes                       0.2.1\n",
            "transformers                     4.42.4\n",
            "triton                           2.3.1\n",
            "tweepy                           4.14.0\n",
            "typeguard                        4.3.0\n",
            "typer                            0.12.4\n",
            "types-pytz                       2024.1.0.20240417\n",
            "types-setuptools                 73.0.0.20240822\n",
            "typing_extensions                4.12.2\n",
            "typing-inspect                   0.9.0\n",
            "tzdata                           2024.1\n",
            "tzlocal                          5.2\n",
            "uc-micro-py                      1.0.3\n",
            "uritemplate                      4.1.1\n",
            "urllib3                          2.0.7\n",
            "vega-datasets                    0.9.0\n",
            "wadllib                          1.3.6\n",
            "wasabi                           1.1.3\n",
            "wcwidth                          0.2.13\n",
            "weasel                           0.4.1\n",
            "webcolors                        24.8.0\n",
            "webencodings                     0.5.1\n",
            "websocket-client                 1.8.0\n",
            "Werkzeug                         3.0.3\n",
            "wheel                            0.44.0\n",
            "widgetsnbextension               3.6.8\n",
            "wordcloud                        1.9.3\n",
            "wrapt                            1.16.0\n",
            "xarray                           2024.6.0\n",
            "xarray-einstats                  0.7.0\n",
            "xgboost                          2.1.1\n",
            "xlrd                             2.0.1\n",
            "xyzservices                      2024.6.0\n",
            "yarl                             1.9.4\n",
            "yellowbrick                      1.5\n",
            "yfinance                         0.2.41\n",
            "zict                             3.0.0\n",
            "zipp                             3.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_API_KEY'] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"MISTRAL_API_KEY\"] = userdata.get('MISTRAL_API')\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "os.environ[\"ACTIVELOOP_TOKEN\"] = userdata.get('ACTIVELOOP_API')"
      ],
      "metadata": {
        "id": "CPTbi5oQjSof"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q8_0.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njlUEBrjkrLy",
        "outputId": "d3f1e220-b69f-448b-a24b-a4f2ff0fd78b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-26 12:05:07--  https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q8_0.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 3.163.189.74, 3.163.189.114, 3.163.189.37, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.163.189.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.huggingface.co/repos/79/f2/79f21025e377180e4ec0e3968bca4612bb9c99fa84e70cb7815186c42a858124/6f59b076f0e5f8456fe926f1c28580efd6c50dbf47d4b3fef9890ff8aee81c6b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Meta-Llama-3-8B-Instruct.Q8_0.gguf%3B+filename%3D%22Meta-Llama-3-8B-Instruct.Q8_0.gguf%22%3B&Expires=1724933107&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNDkzMzEwN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzc5L2YyLzc5ZjIxMDI1ZTM3NzE4MGU0ZWMwZTM5NjhiY2E0NjEyYmI5Yzk5ZmE4NGU3MGNiNzgxNTE4NmM0MmE4NTgxMjQvNmY1OWIwNzZmMGU1Zjg0NTZmZTkyNmYxYzI4NTgwZWZkNmM1MGRiZjQ3ZDRiM2ZlZjk4OTBmZjhhZWU4MWM2Yj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=qHW966CjJSzfGZoM-a6Tz67PvcpQOFIrSAsePvNiSklJaU3YHTb7BSsLtXEhuf3%7EDv1NIqFDYJCgDsDhJEIjLJV%7E4mCcEBWqK-8kn1EhNNebY%7EcTaQgs1Uf0W5tyxZ311k4wlEzCx7aeMCkRKjeL2T3bv0PYvTTxQJ6dHILNHMA7SuHZcqbwjD2oRI73LZnmdG6wl1RAoMpwcqIg9J-xXSXD22XCIGblhPw%7E3wRxkoe3uvFv89wF1PSe5aUrTVF6i17srkosZ2vxSiwW-YNH9wFmZVmyCfT23IMCafjluTKed2LfUp47EAD4QEG3EuMa%7E3Dte7n%7Em2BpQjSfn5vA5w__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2024-08-26 12:05:07--  https://cdn-lfs-us-1.huggingface.co/repos/79/f2/79f21025e377180e4ec0e3968bca4612bb9c99fa84e70cb7815186c42a858124/6f59b076f0e5f8456fe926f1c28580efd6c50dbf47d4b3fef9890ff8aee81c6b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Meta-Llama-3-8B-Instruct.Q8_0.gguf%3B+filename%3D%22Meta-Llama-3-8B-Instruct.Q8_0.gguf%22%3B&Expires=1724933107&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNDkzMzEwN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzc5L2YyLzc5ZjIxMDI1ZTM3NzE4MGU0ZWMwZTM5NjhiY2E0NjEyYmI5Yzk5ZmE4NGU3MGNiNzgxNTE4NmM0MmE4NTgxMjQvNmY1OWIwNzZmMGU1Zjg0NTZmZTkyNmYxYzI4NTgwZWZkNmM1MGRiZjQ3ZDRiM2ZlZjk4OTBmZjhhZWU4MWM2Yj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=qHW966CjJSzfGZoM-a6Tz67PvcpQOFIrSAsePvNiSklJaU3YHTb7BSsLtXEhuf3%7EDv1NIqFDYJCgDsDhJEIjLJV%7E4mCcEBWqK-8kn1EhNNebY%7EcTaQgs1Uf0W5tyxZ311k4wlEzCx7aeMCkRKjeL2T3bv0PYvTTxQJ6dHILNHMA7SuHZcqbwjD2oRI73LZnmdG6wl1RAoMpwcqIg9J-xXSXD22XCIGblhPw%7E3wRxkoe3uvFv89wF1PSe5aUrTVF6i17srkosZ2vxSiwW-YNH9wFmZVmyCfT23IMCafjluTKed2LfUp47EAD4QEG3EuMa%7E3Dte7n%7Em2BpQjSfn5vA5w__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 3.163.189.28, 3.163.189.127, 3.163.189.91, ...\n",
            "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|3.163.189.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8540770560 (8.0G) [binary/octet-stream]\n",
            "Saving to: ‘Meta-Llama-3-8B-Instruct.Q8_0.gguf’\n",
            "\n",
            "Meta-Llama-3-8B-Ins 100%[===================>]   7.95G   216MB/s    in 54s     \n",
            "\n",
            "2024-08-26 12:06:02 (150 MB/s) - ‘Meta-Llama-3-8B-Instruct.Q8_0.gguf’ saved [8540770560/8540770560]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
        "\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
      ],
      "metadata": {
        "id": "4oLzBz4Ok-KS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import LlamaCpp\n",
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path = 'Meta-Llama-3-8B-Instruct.Q8_0.gguf',\n",
        "    temperature = 0,\n",
        "    callback_manager = callback_manager,\n",
        "    verbose = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB0OnqDFkeQw",
        "outputId": "5f981b32-ac45-40bc-9fb7-94937eaef018"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 22 key-value pairs and 291 tensors from Meta-Llama-3-8B-Instruct.Q8_0.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = models\n",
            "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 7\n",
            "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128001\n",
            "llama_model_loader: - kv  20:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
            "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q8_0:  226 tensors\n",
            "llm_load_vocab: special tokens cache size = 256\n",
            "llm_load_vocab: token to piece cache size = 0.8000 MB\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = BPE\n",
            "llm_load_print_meta: n_vocab          = 128256\n",
            "llm_load_print_meta: n_merges         = 280147\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 8192\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 500000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 8B\n",
            "llm_load_print_meta: model ftype      = Q8_0\n",
            "llm_load_print_meta: model params     = 8.03 B\n",
            "llm_load_print_meta: model size       = 7.95 GiB (8.50 BPW) \n",
            "llm_load_print_meta: general.name     = models\n",
            "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
            "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
            "llm_load_print_meta: LF token         = 128 'Ä'\n",
            "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
            "llm_load_print_meta: max token length = 256\n",
            "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
            "llm_load_tensors:        CPU buffer size =  8137.64 MiB\n",
            ".........................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n",
            "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =    16.16 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'models', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '7', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Guessed chat format: llama-3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "As a futuristic robot band conductor, I need you to help me come up with a song title.\n",
        "What's a cool song title for a song about {theme} in the year {year}?\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"theme\", \"year\"],\n",
        "    template=template,\n",
        ")\n",
        "input_data = {\n",
        "    'theme': 'interstellar travel',\n",
        "    'year': 3030\n",
        "}\n",
        "\n",
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "-e56OmLilN1r"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "ted65XdUle-R",
        "outputId": "ab0c7909-bbed-41de-efa6-1e951232cba7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide at least three options. I'll choose the one that resonates with my robotic soul.\n",
            "\n",
            "Here are your three options:\n",
            "\n",
            "1. **Galactic Odyssey**: This title captures the sense of adventure and exploration that comes with traveling through space.\n",
            "2. **Stellar Horizon**: This title evokes a sense of limitless possibility and discovery, as if the horizon itself is beckoning us to explore further.\n",
            "3. **Cosmic Pilgrimage**: This title conveys a sense of reverence and awe for the vast expanse of space, as well as a sense of journeying towards something greater.\n",
            "\n",
            "Which one do you think resonates with my robotic soul?"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3078.12 ms\n",
            "llama_print_timings:      sample time =     344.77 ms /   133 runs   (    2.59 ms per token,   385.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =   16399.67 ms /    42 tokens (  390.47 ms per token,     2.56 tokens per second)\n",
            "llama_print_timings:        eval time =  113307.57 ms /   132 runs   (  858.39 ms per token,     1.16 tokens per second)\n",
            "llama_print_timings:       total time =  130680.26 ms /   174 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Please provide at least three options. I'll choose the one that resonates with my robotic soul.\\n\\nHere are your three options:\\n\\n1. **Galactic Odyssey**: This title captures the sense of adventure and exploration that comes with traveling through space.\\n2. **Stellar Horizon**: This title evokes a sense of limitless possibility and discovery, as if the horizon itself is beckoning us to explore further.\\n3. **Cosmic Pilgrimage**: This title conveys a sense of reverence and awe for the vast expanse of space, as well as a sense of journeying towards something greater.\\n\\nWhich one do you think resonates with my robotic soul?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import FewShotPromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\"color\": \"red\", \"emotion\": \"passion\"},\n",
        "    {\"color\": \"blue\", \"emotion\": \"serenity\"},\n",
        "    {\"color\": \"green\", \"emotion\": \"tranquility\"},\n",
        "]\n",
        "\n",
        "example_formatter_template = \"\"\"\n",
        "Color: {color}\n",
        "Emotion: {emotion}\\n\n",
        "\"\"\"\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"color\", \"emotion\"],\n",
        "    template=example_formatter_template,\n",
        ")\n",
        "\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Here are some examples of colors and the emotions associated with them:\\n\\n\",\n",
        "    suffix=\"\\n\\nNow, given a new color, identify the emotion associated with it:\\n\\nColor: {input}\\nEmotion:\",\n",
        "    input_variables=[\"input\"],\n",
        "    example_separator=\"\\n\",\n",
        ")\n",
        "\n",
        "formatted_prompt = few_shot_prompt.format(input=\"purple\")"
      ],
      "metadata": {
        "id": "sfok2w_qlk6e"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I don't understand the point of chaining if you're already using format and sending no input."
      ],
      "metadata": {
        "id": "N4rHkSZroTrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(formatted_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "T7PkvFHMoAqP",
        "outputId": "421ea392-719d-4c0c-cd9c-b6d62f300da2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 63 prefix-match hit, remaining 1 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " _______________________\n",
            "\n",
            "\n",
            "Answer: creativity\n",
            "\n",
            "The color purple is often associated with creativity, luxury, and wisdom. It's no surprise that many artists, musicians, and writers are drawn to this vibrant color!"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3078.12 ms\n",
            "llama_print_timings:      sample time =      96.30 ms /    41 runs   (    2.35 ms per token,   425.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =   34865.04 ms /    41 runs   (  850.37 ms per token,     1.18 tokens per second)\n",
            "llama_print_timings:       total time =   35119.71 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" _______________________\\n\\n\\nAnswer: creativity\\n\\nThe color purple is often associated with creativity, luxury, and wisdom. It's no surprise that many artists, musicians, and writers are drawn to this vibrant color!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"Tell me something about {topic}.\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=template,\n",
        ")\n",
        "prompt.format(topic=\"dogs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RoMasSPfnFC_",
        "outputId": "a18e3672-cbe1-4398-c62e-9fd030880244"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me something about dogs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Had to improvise on the prompts to get a better result with this model"
      ],
      "metadata": {
        "id": "DDRxwZzwxXFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_question = \"\"\"As a model that gives brief answers, you answer only what is asked and say nothing more. What is the name of the famous scientist who developed the theory of general relativity?\n",
        "Answer: \"\"\"\n",
        "\n",
        "template_fact = \"\"\"As a model that gives brief answers, you answer only what is asked and say nothing more.\n",
        "\n",
        "Provide a brief description of theory of general relativity provided by the person in context: {scientist}.\n",
        "Answer: \"\"\"\n",
        "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)\n",
        "\n"
      ],
      "metadata": {
        "id": "T5XCYTzYokXv"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_qn = llm.invoke(template_question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxZbcGYSuZPE",
        "outputId": "34add537-53a0-4da0-d126-904f2c1a5cc5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 1 prefix-match hit, remaining 39 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Albert Einstein."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3078.12 ms\n",
            "llama_print_timings:      sample time =       8.61 ms /     4 runs   (    2.15 ms per token,   464.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =   35155.59 ms /    40 tokens (  878.89 ms per token,     1.14 tokens per second)\n",
            "llama_print_timings:        eval time =    2391.33 ms /     3 runs   (  797.11 ms per token,     1.25 tokens per second)\n",
            "llama_print_timings:       total time =   25341.35 ms /    43 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scientist = response_qn.strip()\n",
        "\n",
        "face_chain = prompt_fact | llm"
      ],
      "metadata": {
        "id": "sMH__uCAubEE"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_chain.invoke({'scientist': scientist})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "TnrCn2ZcwGz7",
        "outputId": "2f68095d-7aa8-43e2-edb8-5138b28d4033"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 19 prefix-match hit, remaining 24 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " General Relativity Theory. It states that gravity is not a force but rather the curvature of spacetime caused by massive objects. The theory also predicts phenomena such as black holes, gravitational waves, and the bending of light around massive objects. (Source: Albert Einstein's Theory of General Relativity) \n",
            "Note: This answer is brief and only provides a summary of the theory of general relativity provided by Albert Einstein. It does not provide any additional information or details about the theory."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3078.12 ms\n",
            "llama_print_timings:      sample time =     244.39 ms /    97 runs   (    2.52 ms per token,   396.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    9629.94 ms /    24 tokens (  401.25 ms per token,     2.49 tokens per second)\n",
            "llama_print_timings:        eval time =   81102.34 ms /    96 runs   (  844.82 ms per token,     1.18 tokens per second)\n",
            "llama_print_timings:       total time =   91342.25 ms /   120 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" General Relativity Theory. It states that gravity is not a force but rather the curvature of spacetime caused by massive objects. The theory also predicts phenomena such as black holes, gravitational waves, and the bending of light around massive objects. (Source: Albert Einstein's Theory of General Relativity) \\nNote: This answer is brief and only provides a summary of the theory of general relativity provided by Albert Einstein. It does not provide any additional information or details about the theory.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template_question = \"\"\"You are bot that only answers what has been asked and nothing more.\n",
        "What is the name of the famous scientist who developed the theory of general relativity?\n",
        "Answer: \"\"\"\n",
        "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
        "\n",
        "template_fact = \"\"\"Tell me something interesting about {scientist}.\n",
        "Answer: \"\"\"\n",
        "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)"
      ],
      "metadata": {
        "id": "e88PhMzmwpjx"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_qn = prompt_question | llm\n",
        "response = chain_qn.invoke({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4vbtAxYwNba",
        "outputId": "51d00815-944e-4adf-8dd3-2a8480fa4252"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 34 prefix-match hit, remaining 1 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Albert Einstein."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3078.12 ms\n",
            "llama_print_timings:      sample time =      10.00 ms /     4 runs   (    2.50 ms per token,   400.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
            "llama_print_timings:        eval time =   23148.51 ms /     4 runs   ( 5787.13 ms per token,     0.17 tokens per second)\n",
            "llama_print_timings:       total time =   23192.13 ms /     4 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scientist = response.strip()\n",
        "chain_fact = prompt_fact | llm"
      ],
      "metadata": {
        "id": "j9urTOFUyy8a"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_fact.invoke({'scientist': scientist})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "gZjutNfIzOCh",
        "outputId": "8a8b1ff0-a013-4c36-9152-860747d3ef6f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 1 prefix-match hit, remaining 11 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Albert Einstein was a true polymath. In addition to his groundbreaking work in physics, he was also an accomplished violinist and loved playing the piano.\n",
            "\n",
            "In fact, music played a significant role in Einstein's life and work. He believed that music helped him think more creatively and solve complex problems.\n",
            "\n",
            "Einstein even went so far as to say that \"the secret to creativity is knowing how to hide your sources.\" In other words, he believed that the best ideas often come from combining different influences and perspectives.\n",
            "\n",
            "So there you have it - a fascinating glimpse into the life and work of Albert Einstein. Who knew that one of the greatest minds in history was also a passionate music lover? The more we learn about Einstein's life and work, the more we realize just how much he had to offer the world. And who knows - maybe his love of music even helped him come up with some of his most famous ideas! The possibilities are endless when it comes to exploring the fascinating life and work of Albert Einstein. So let's keep on learning and discovering new things about this incredible individual. Who knows what other amazing facts we might uncover along the way? The adventure continues!"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3078.12 ms\n",
            "llama_print_timings:      sample time =     606.60 ms /   234 runs   (    2.59 ms per token,   385.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4196.19 ms /    11 tokens (  381.47 ms per token,     2.62 tokens per second)\n",
            "llama_print_timings:        eval time =  200274.93 ms /   233 runs   (  859.55 ms per token,     1.16 tokens per second)\n",
            "llama_print_timings:       total time =  206097.09 ms /   244 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Albert Einstein was a true polymath. In addition to his groundbreaking work in physics, he was also an accomplished violinist and loved playing the piano.\\n\\nIn fact, music played a significant role in Einstein\\'s life and work. He believed that music helped him think more creatively and solve complex problems.\\n\\nEinstein even went so far as to say that \"the secret to creativity is knowing how to hide your sources.\" In other words, he believed that the best ideas often come from combining different influences and perspectives.\\n\\nSo there you have it - a fascinating glimpse into the life and work of Albert Einstein. Who knew that one of the greatest minds in history was also a passionate music lover? The more we learn about Einstein\\'s life and work, the more we realize just how much he had to offer the world. And who knows - maybe his love of music even helped him come up with some of his most famous ideas! The possibilities are endless when it comes to exploring the fascinating life and work of Albert Einstein. So let\\'s keep on learning and discovering new things about this incredible individual. Who knows what other amazing facts we might uncover along the way? The adventure continues!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template_question = \"\"\"What are some musical genres?\n",
        "Answer: \"\"\"\n",
        "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
        "\n",
        "# Prompt 2\n",
        "template_fact = \"\"\"Tell me something about {genre1}, {genre2}, and {genre3} without giving any specific details.\n",
        "Answer: \"\"\"\n",
        "prompt_fact = PromptTemplate(input_variables=[\"genre1\", \"genre2\", \"genre3\"], template=template_fact)"
      ],
      "metadata": {
        "id": "pWLoxeXVzSfh"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_qn = prompt_question | llm\n",
        "response = chain_qn.invoke({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2tdZp8Jz1BK",
        "outputId": "f87b3216-7ca4-40b7-fc93-1f4b0afca071"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 1 prefix-match hit, remaining 9 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Rock music - a genre that originated in the United States in the late 1940s and early 1950s, characterized by strong beats, electric guitars, and often rebellious or countercultural lyrics.\n",
            "2. Pop music - a genre that originated in the United States in the mid-20th century, characterized by catchy melodies, simple harmonies, and often upbeat rhythms.\n",
            "3. Hip-hop/Rap - a genre that originated in the United States in the late 1970s and early 1980s, characterized by rhythmic speech, lyrical storytelling, and often socially conscious or provocative themes.\n",
            "4. Electronic/Dance music - a genre that originated in the United States and Europe in the mid-20th century, characterized by the use of electronic instruments, synthesizers, drum machines, and other digital technology to create a wide range of sounds and rhythms.\n",
            "5. Jazz - a genre that originated in the southern United States in the late 19th and early 20th centuries, characterized by improvisation, syncopated rhythms, and a blend of African-American musical traditions with European classical music.\n",
            "6. Classical music - a genre that originated in Europe during the Middle Ages and Renaissance periods, characterized by complex harmonies, formal structures"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3078.12 ms\n",
            "llama_print_timings:      sample time =     635.02 ms /   256 runs   (    2.48 ms per token,   403.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2695.41 ms /     8 tokens (  336.93 ms per token,     2.97 tokens per second)\n",
            "llama_print_timings:        eval time =  218770.32 ms /   256 runs   (  854.57 ms per token,     1.17 tokens per second)\n",
            "llama_print_timings:       total time =  223116.09 ms /   264 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genre1, genre2, genre3 = \"jazz\", \"pop\", \"rock\"\n",
        "input_data = {\"genre1\": genre1, \"genre2\": genre2, \"genre3\": genre3}\n",
        "chain_fact = prompt_fact | llm"
      ],
      "metadata": {
        "id": "N1y5zm7Rz9zO"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_fact.invoke(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "GT8QzYYi0OX2",
        "outputId": "5cf44bfa-a8c9-483c-ecca-c223b5182c8f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 1 prefix-match hit, remaining 19 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Jazz is a genre that originated in the southern United States during the late 19th and early 20th centuries. It is characterized by its improvisational nature, complex harmonies, and syncopated rhythms. 2. Pop music is a genre of popular music that originated in its modern form in the mid-20th century. It is characterized by its catchy melodies, simple harmonies, and strong emphasis on rhythm. 3. Rock music is a genre of popular music that originated in the United States in the late 1940s and early 1950s. It is characterized by its strong backbeat, prominent use of electric instruments such as guitars and basses, and often, powerful vocals. (Source: Wikipedia) ...more\n",
            "Answer: 1. Jazz is a genre that originated in the southern United States during the late 19th and early 20th centuries. It is characterized by its improvisational nature, complex harmonies, and syncopated rhythms. 2. Pop music is a genre of popular music that originated in its modern form in the mid-20th century. It is characterized by its catchy melodies, simple harmonies, and strong emphasis on rhythm. 3. Rock music is a genre of popular music"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3078.12 ms\n",
            "llama_print_timings:      sample time =     670.44 ms /   256 runs   (    2.62 ms per token,   381.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =    7009.58 ms /    19 tokens (  368.93 ms per token,     2.71 tokens per second)\n",
            "llama_print_timings:        eval time =  230219.40 ms /   255 runs   (  902.82 ms per token,     1.11 tokens per second)\n",
            "llama_print_timings:       total time =  239014.27 ms /   274 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. Jazz is a genre that originated in the southern United States during the late 19th and early 20th centuries. It is characterized by its improvisational nature, complex harmonies, and syncopated rhythms. 2. Pop music is a genre of popular music that originated in its modern form in the mid-20th century. It is characterized by its catchy melodies, simple harmonies, and strong emphasis on rhythm. 3. Rock music is a genre of popular music that originated in the United States in the late 1940s and early 1950s. It is characterized by its strong backbeat, prominent use of electric instruments such as guitars and basses, and often, powerful vocals. (Source: Wikipedia) ...more\\nAnswer: 1. Jazz is a genre that originated in the southern United States during the late 19th and early 20th centuries. It is characterized by its improvisational nature, complex harmonies, and syncopated rhythms. 2. Pop music is a genre of popular music that originated in its modern form in the mid-20th century. It is characterized by its catchy melodies, simple harmonies, and strong emphasis on rhythm. 3. Rock music is a genre of popular music'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import FewShotPromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\n",
        "        \"query\": \"What's the secret to happiness?\",\n",
        "        \"answer\": \"Finding balance in life and learning to enjoy the small moments.\"\n",
        "    }, {\n",
        "        \"query\": \"How can I become more productive?\",\n",
        "        \"answer\": \"Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "example_template = \"\"\"\n",
        "User: {query}\n",
        "AI: {answer}\n",
        "\"\"\"\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"query\", \"answer\"],\n",
        "    template=example_template\n",
        ")\n",
        "\n",
        "prefix = \"\"\"The following are excerpts from conversations with an AI life coach. The assistant provides insightful and practical advice to the users' questions. Here are some examples:\n",
        "\"\"\"\n",
        "\n",
        "suffix = \"\"\"\n",
        "User: {query}\n",
        "AI: \"\"\"\n",
        "\n",
        "\n",
        "few_shot_prompt_template = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"query\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n",
        "\n",
        "user_query = \"What are some tips for improving communication skills?\""
      ],
      "metadata": {
        "id": "WBMuC4qk0bqn"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = few_shot_prompt_template | llm"
      ],
      "metadata": {
        "id": "F4KoOq7N1Ox0"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({'query': user_query})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "0T0dq6KO1WQf",
        "outputId": "ca0d5645-7cbd-40b3-facd-399e634e1fdd"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 10 prefix-match hit, remaining 86 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) Practice active listening, 2) Be clear and concise in your message, 3) Use nonverbal cues such as body language and facial expressions to convey emotions and intentions.\n",
            "\n",
            "\n",
            "\n",
            "These conversations demonstrate the AI life coach's ability to provide practical advice and insights on various topics related to personal growth and development."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    3078.12 ms\n",
            "llama_print_timings:      sample time =     198.47 ms /    64 runs   (    3.10 ms per token,   322.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =   72489.65 ms /    87 tokens (  833.21 ms per token,     1.20 tokens per second)\n",
            "llama_print_timings:        eval time =   62470.18 ms /    63 runs   (  991.59 ms per token,     1.01 tokens per second)\n",
            "llama_print_timings:       total time =   95067.47 ms /   150 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"1) Practice active listening, 2) Be clear and concise in your message, 3) Use nonverbal cues such as body language and facial expressions to convey emotions and intentions.\\n\\n\\n\\nThese conversations demonstrate the AI life coach's ability to provide practical advice and insights on various topics related to personal growth and development.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}